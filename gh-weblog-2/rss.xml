<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<atom:link href="http://pomax.github.io/gh-weblog-2/rss.xml" rel="self" type="application/rss+xml" />
<title>Pomax.github.io</title>
<description>My blog on github</description>
<link>http://pomax.github.io</link>
<lastBuildDate>Sun, 31 Jan 2016 19:35:30 GMT</lastBuildDate>
<pubDate>Sun, 31 Jan 2016 19:35:30 GMT</pubDate>
<ttl>1440</ttl>
<item>
<title> A blog post about kitchen knives</title>
<description>&lt;p&gt;I've been promising to write this blog post for a while after joking about how the fair number of knives I use in the kitchen would probably fill an entire blog post, but for reasons that have been lost to time never got to it. That changes now.&lt;/p&gt;
&lt;p&gt;I like working in the kitchen, I started as a kid, kept it up as a student, and had the pleasure to have access to a good kitchen with gas range after moving to Canada from the Netherlands. When it came time to buy our own house, we specifically bought one with a large kitchen and gas range, and I still get my cook on on a daily -if not more- basis.&lt;/p&gt;
&lt;p&gt;Now, cookery requires ingredients, and ingredients quite often require cutting, so you buy a cheap knife set, you use two or three of them frequently, and you can get by quite well. The price of a knife set does not determine how well the knives will work, and some of the more expensive ones (I'm looking at you, Global) are absolutely terrible to have to work with on a daily basis. Better to get a cheap set that cuts well and have a friend grind down the handle a bit where the metal bits and wooden bits don't quite line up, than to pay ten times as much or more for great quality that's horrible to work with.&lt;/p&gt;
&lt;p&gt;Now, two or three knives is literally all you need. If I were caught in a situation where I had to prepare food for 40 people and all I had was a chef knife and a paring knife, I'd be fine. But they do make specialty knives, and having them makes certain tasks either more fun, or much easier, so I've picked up a few knives over the years and of those, this blog post will highlight the ones I use regularly, meaning either daily, or at least several times a month. Except for two, but we'll get to them.&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-01.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Let's talk about this collection, shall we?&lt;/p&gt;
&lt;h2 id="the-chef-knife"&gt;The chef knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-02.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;The chef knife is, as far as I'm concerned, the absolute minimum necessary to "do everything". It can slice, it can dice (well, with your help), it can chop, it can pare (while a little inconveniently, it absolutely can), it can fillet, it can crush, as far as I'm concerned it is the only knife you &lt;strong&gt;need&lt;/strong&gt; in a kitchen. Although that doesn't mean you should use it for all those things because you'll probably have at least one or two knives that can do one or more of those things better. &lt;/p&gt;
&lt;p&gt;I have a few chef knives, but these are the two I use on a daily basis. The top is essentially my backup for when more than one person's in the kitchen, if it's just me I'll typically use... well, perhaps the level of wear will give it away: I use the knife with the broken tip. It's from a $30 knife set I bought over 10 years ago, and is as sharp as any $200 knife. In terms of actual weight, it's fairly heavy, but it's extremely well balanced so it feels like it has very little true weight to it, and it dances around in your hand if you want it to. Yes, that's the level of satisfaction a nice kitchen knife can give &lt;/p&gt;
&lt;p&gt;I use these for big cuts, slicing, as well as chopping up things. Bog standard use really.&lt;/p&gt;
&lt;h2 id="the-utility-knife"&gt;The utility knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-03.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;The utility knife is for smaller jobs. The blade's too short for most things a chef knife is good for, but it's great for incisions and stripping (both of those apply to vegetables as much as to meats).&lt;/p&gt;
&lt;h2 id="the-paring-knife"&gt;The paring knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-04.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;A paring knife is the scalpel of the basic set. It's not good for any kind of slicing, but it's great for precision cuts, and cutting things away from each other with minimum spill-over, or creating small cutouts (like taking a stem out of a bell pepper. No need to waste tasty vegetable goodness by cutting off the entire top). &lt;/p&gt;
&lt;h2 id="a-nice-sharp-cleaver"&gt;A nice sharp cleaver&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-05.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;While this looks like a super heavy thing, and it's certainly heavier than a regular knife, this old Solingen cleaver is essentially the same as a thick Chinese cleaver. It has a sharp edge, and can be used for cutting, and because of the geometry of the blade near the handle, shucking oysters or other shellfish, and of course it's a cleaver so you can use it to cleave, although it's mostly for cleaving &lt;em&gt;soft&lt;/em&gt; things.&lt;/p&gt;
&lt;p&gt;Simple rule: things with sharp edges are meant for cutting, not hitting. The value in a cleaver is its size and solidity; do the initial cut, drive the cleaver in, then drive it through. The softer the thing you're cleaving, the more you can "chop" rather than drive, but this is not TV, and you don't wield a regular cleaver like it's a hatchet.   &lt;/p&gt;
&lt;p&gt;For instance: chunking up Chinese barbecue pork: yes. cleaving through a lamb shoulder: no. Splitting a squash: absolutely. Chopping a chicken thigh in half: ... kind of not, no. I mean, you can if you absolutely have to, but really you want the next item on this list instead.&lt;/p&gt;
&lt;h2 id="a-nice-not-really-sharp-bone-cleaver"&gt;A nice not-really-sharp bone cleaver&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-06.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;This is a real cleaver in the sense of "what people think of when you say cleaver". It basically a kitchen axe with a relatively dull edge. You don't cut things with this (you plain old can't) but you use it as a splitter to get through bones. Or, sometimes, things that have frozen up pretty solid. &lt;/p&gt;
&lt;p&gt;Unlike a sharp cleaver, bone cleavers &lt;em&gt;are&lt;/em&gt; wielded like hatchets: it's pretty much what they are. I obviously don't use this every day, it's a specialty knife (if we can really still call it a knife) but this is the only tool I want to use when I do need to use it.&lt;/p&gt;
&lt;h2 id="a-tako-sashimi-knife"&gt;A tako sashimi knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-07.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;"Japanese knives!", aye. The tako sashimi knife is, not surprisingly, a sashimi knife, meaning it's intended for precision-slicing. The "tako" part in the name implies it's intended for octopus cutting, but it's shaped well enough to be used for fish and shellfish, too. It might look a bit long, but honestly I'm looking into replacing it with a longer version: sashimi is raw, which means nothing will have been done to the cut to hide imprecisions or imperfections, and the human tongue is an amazing organ: it will detect rough cuts. The longer the knife, the longer you can make a single, constant pressure cut, which means the cut surface will be absolutely smooth. Unlike a chef knife, where you're often cutting away from yourself, you cut towards yourself with a sashimi knife. Even seen or bowed a violin? It's pretty much like that. Very little pressure, let the knife do the cutting as you pull it in.&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-08.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Unlike the previous knives, this is a single sided knife: it's perfectly flat on the left side, and ground to an extremely sharp edge on the other. At least for sashimi, this means you don't disturb half the cut by "pushing it out of the way", which a normal sided knife will do.&lt;/p&gt;
&lt;h2 id="a-deba-fish-knife"&gt;A deba fish knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-09.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Fish knife! This is a thick, heavy knife with a single sided edge. It's extremely sharp, and great for deboning fish. If you have an whole salmon (and I live in Vancouver, a whole salmon can be yours for about $10) then this knife is all you need to turn it into two beautiful full length fillets.&lt;/p&gt;
&lt;h2 id="an-usuba-vegetable-knife"&gt;An usuba vegetable knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-10.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Finally, the Japanese vegetable knife. Again, single sided edge, and it's incredibly sharp. It sits at the intersection of chef knife and cleaver, and is create for splitting not-too-hard vegetables, as well as chopping up vegetables if presentation is going to matter, like uniformly hair-fine julienne, peeling a cucumber to get the entire skin as a single sheet, getting wafer thin slices of vegetable, et cetera.&lt;/p&gt;
&lt;p&gt;I love this knife to bits. &lt;/p&gt;
&lt;h2 id="the-ol-bread-knife"&gt;The ol' bread knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-15.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;On to pure utility: the bread knife. Some people don't have one, some do but never use it, in our household this thing is pretty much used on a daily basis. It's not actually all that good at slicing bread, but it's a great knife for cutting frozen items, as well as "opening up" a bread for slicing, which basically means cutting it in half so that the next knife on the list can be used...&lt;/p&gt;
&lt;h2 id="a-bread-saw"&gt;A bread saw&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-11.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;That's right, it's a saw. On a handle. For slicing bread. After you open up a bread with the regular breadknife, all the other slices are simply "put this on bread so that the wood touches the side and the saw touches the top. Saw off slice". It is perfect.&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-12.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;It's also literally just a saw blade. I stopped counting the number of times I accidentally cut myself on this thing. Most knives don't draw blood just by being tapped. This thing? No mercy.&lt;/p&gt;
&lt;h2 id="keeping-knives-sharp"&gt;Keeping knives sharp&lt;/h2&gt;
&lt;p&gt;And let's not forget the things we need to make sure knives stay usable. Knife edges wear off over time and with use, and hard as metal is, a very sharp blade is thin, and can easily dent or chip. To deal with this, there's three tools in my kitchen for making sure the knives stay usable. &lt;/p&gt;
&lt;h3 id="a-good-steel"&gt;a good steel&lt;/h3&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-14.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;First off, a good steel. Steels are not for sharpening a knife, they're for making sure any dents in the cutting edge are smoothed out by "steeling" it: rubbing the edge along the steel, doing both sides to make sure dents in either direction and smoothed back in line with the rest of the edge. Do this when you're done with your knife after cutting something that offered a bit of resistance and your knife'll last a bit longer. &lt;/p&gt;
&lt;h3 id="grind-stone-s-and-carbide-shaver"&gt;grind stone(s) and carbide shaver&lt;/h3&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-13.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Of course, steeling isn't sharpening, and your knife &lt;em&gt;will&lt;/em&gt; lose its edge eventually. When that happens, it's time to whip out the grinding stones. I have a combination 400 grit/2000 grit whetstone, and badly dulled knives first get a treatment at 400 before moving on to 2000.&lt;/p&gt;
&lt;p&gt;Finally there's that little "speedy sharp" thing: that's a carbide steel strip on a handle. A word of warning: this is &lt;em&gt;not&lt;/em&gt; a sharpener. This is a shaver, and does what that word implies: the carbide steel strip is much, much stronger than the metal used to make  your knife, and running this across the cutting edge literally shaves off some of the metal. It's a very fast way to give a knife a quick edge, but you've just reduced your knife width by far more than you would if you used a sharpening stone. Use this as your only method of sharpening and you're literally going to just run out of knife. That said, I use this to quickly strip a knife of whatever oxidation or environmental coating it may have picked up when I bake baguettes, where getting a good scoring across the loaves before the bread goes into the oven is far more important to me than wearing out a knife. Just stroke the edge with minimal force a few times and you're good to go. As long as you remember to also give the knife a quick rinse because again: you're shaving it. There will be residue.   &lt;/p&gt;
&lt;h1 id="and-that-s-it-"&gt;And that's it.&lt;/h1&gt;
&lt;p&gt;That's all the knives I use regularly enough to feel they warrant mention - Notably missing are my Chinese cleaves (#1, #2, and #5) that I basically stopped using because between the chef knives and Japanese knives, there's nothing they're actually better at, and while nifty, things like grapefruit knives are so special purpose that if you need them, you know why, and if you don't know why, you won't need them.&lt;/p&gt;
</description>
<category>Kitchen</category>
<category>Knives</category>
<category>Knife</category>
<link>http://pomax.github.io/#gh-weblog-1454267122337</link>
<guid>http://pomax.github.io/#gh-weblog-1454267122337</guid>
<pubDate>Sun, 31 Jan 2016 19:05:22 GMT</pubDate>
</item>
<item>
<title> "git init" your way to peace of mind.</title>
<description>&lt;p&gt;This is going to be a short post, but it's one that can make the difference between you being happy, and crying with your head in your hands because you absolutely ruined a file and hit save.  I'm basically going to tell you to use version control for stuff that matters, but rather than letting you figure out how to do that, I'm simply going to straight up tell you.&lt;/p&gt;
&lt;h2 id="what-do-i-need-version-control-for-i-don-t-program"&gt;What do I need version control for, I don't program&lt;/h2&gt;
&lt;p&gt;Who cares about programming? Do you write text on your computer? Maybe Word docs? A personal web page? Blog entries as .txt files you'll copy-paste into wordpress later? It really doesn't matter: the real question is "do you have folders/directories with data in them that you change every now and then, and that you might mess up because you can accidentally hit save and overwrite them, or accidentally hit delete and lose them forever?".&lt;/p&gt;
&lt;p&gt;Because the answer is pretty much guaranteed "yes", and you could try to be diligent about never hitting save or delete, but you're human, and you're going to mess up. Maybe not today, maybe not next week, but chances are pretty much 100% at some point, you'll mess up.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;so use git&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="what-do-i-need-git-for-i-don-t-want-to-put-my-stuff-online"&gt;What do I need "git" for, I don't want to put my stuff online&lt;/h2&gt;
&lt;p&gt;Yeah, common misconception. "git" has nothing to do with "putting stuff online", but has everything to do with "being version control software". In order to be successful version control software, you need to be able to do remote syncing because the vast majority of version controlled data is collaborative data, but it's 100% not necessary for the version control part, so here's what you do:&lt;/p&gt;
&lt;h2 id="safeguard-your-data-from-you-"&gt;Safeguard your data from &lt;em&gt;you&lt;/em&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;install &lt;a href="https://git-scm.com/downloads"&gt;git&lt;/a&gt;. It's a few clicks, just do it.&lt;/li&gt;
&lt;li&gt;For any dir/folder that holds a project you do work on, run "git init". If you are familiar with the command line, it's literally just &lt;code&gt;$&amp;gt; cd your/project/dir&lt;/code&gt; followed by &lt;code&gt;$&amp;gt; git init&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Awesome, you now have version control running for that dir/folder.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="okay-what-s-next-"&gt;Okay, what's next?&lt;/h2&gt;
&lt;p&gt;Every time you make changes to your files, even if you're not done but you made some headway on them and feel like now would be a good time to take a snapshot: take a snapshot!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;$&amp;gt; git add -A&lt;/code&gt; (tell git to look at &lt;em&gt;all&lt;/em&gt; the changes that were made since the last snapshot)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$&amp;gt; git commit -m "give your snapshot a name and/or description here"&lt;/code&gt; (include the quotes)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Done. No syncing with the internet, no complicated workflow stuff, just &lt;code&gt;git add&lt;/code&gt; to add all the changes, and then &lt;code&gt;git commit&lt;/code&gt; to commit the snapshot to the version history.&lt;/p&gt;
&lt;h2 id="okay-i-ve-done-that-and-then-a-few-minutes-later-i-ruined-all-my-files-what-now-"&gt;Okay, I've done that! And then a few minutes later I ruined all my files! What now!?!?!&lt;/h2&gt;
&lt;p&gt;Say you accidentally deleted the files you needed from your project dir, and then to make things worse you also saved empty files on top of that because your text editor spazzed out! Oh no! If you didn't have &lt;code&gt;git&lt;/code&gt; managing your version control, you'd be completely screwed!&lt;/p&gt;
&lt;p&gt;But you have git managing your snapshot history, and as long as you still have its &lt;code&gt;.git&lt;/code&gt; dir, what you just did is effectively insignificant: just tell git to restore your last snapshot:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$&amp;gt; git reset --hard&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And done. All your files are back, in the state they were in during the last snapshot. Sure, you may have lost a few minutes of work, but between that and "I lost everything", I'm pretty sure we'd both pick the few minutes of work lost option.&lt;/p&gt;
&lt;h2 id="it-worked-but-then-i-messed-up-again-and-this-time-i-also-deleted-my-git-directory-"&gt;It worked! But then I messed up &lt;em&gt;again&lt;/em&gt; and this time I also deleted my &lt;code&gt;.git&lt;/code&gt; directory!!&lt;/h2&gt;
&lt;p&gt;That's the only way to make sure &lt;code&gt;git&lt;/code&gt; can't help you anymore. If your workflow is such that you &lt;em&gt;can&lt;/em&gt; delete entire directories, then really you need to get yourself some remote syncing/backup solution. That's kind of out of scope for this short post on "version control your stuff already, you are smart enough to understand the need for it", but you could look at things like &lt;a href="https://www.dropbox.com/"&gt;Dropbox&lt;/a&gt; and/or &lt;a href="https://www.backblaze.com"&gt;backblaze&lt;/a&gt;. If your work is that important, why are you not paying the $5/mo to properly protect &lt;em&gt;all the data on your computer&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;Also, if you have any kind of user account control, make sure to set the &lt;code&gt;.git&lt;/code&gt; directory (but not its content) to read-only, so that even if you accidentally try to delete it, your OS will go "hey you can't actually delete this dir, okay? you're going to have to unlock it before I can do that for you". Depending on your OS the way you do this differs, but again instead of telling you to look up how to do that, I'm just going to tell you.&lt;/p&gt;
&lt;p&gt;On Linux, Unix, and OSX, you can use the terminal to issue &lt;code&gt;$&amp;gt;chmod 0444 .git&lt;/code&gt; in your project's directory, which sets the permissions for the ".git" dir (but not its content) to read-only. Unless you're deleting things with &lt;code&gt;rm&lt;/code&gt;, that dir will be relatively safe now.&lt;/p&gt;
&lt;p&gt;On windows, use any filemanager and right click the dir's folder, and then make sure to check the "read-only" box. On windows deleting the .git dir is usually less of a problem because the dir's marked as "hidden". You'll see it if you're a power user who unhides system and hidden dirs/files, but in normal use you won't see it, and thus won't accidentally delete it.&lt;/p&gt;
&lt;h2 id="i-didn-t-actually-mess-anything-up-but-i-d-like-to-look-at-an-old-snapshot-"&gt;I didn't actually mess anything up, but I'd like to look at an old snapshot...&lt;/h2&gt;
&lt;p&gt;Yeah that's a thing you can do. You can scroll through your snapshot history by using &lt;code&gt;$&amp;gt; git log&lt;/code&gt;, which will tell show your the name/descriptions for each snapshot (which is why you want to at least use sensible naming/descriptions. A single dot is fast to write, but useless if you ever need to go through your history), tied to a git "commit hash", which is a long hexadecimal string that uniquely identifies that snapshot for the git application. Say I need last week's version of a novel I'm writing, because I rewrote half a chapter but I remember there was a paragraph that had super sweet phrasing and I want it back:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;$&amp;gt; git add -A&lt;/code&gt; because I don't want to lose any work&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$&amp;gt; git commit -m "midday work, somedate-2016"&lt;/code&gt; so that git has a snapshot for where I am right now.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$&amp;gt; git log&lt;/code&gt;, to see my history&lt;/li&gt;
&lt;li&gt;Notice that "end of day, Monday, week 2, 2016" has commit "dbcaf87689facb6bcb6f9eb786fs9".&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$&amp;gt;git checkout dbcaf87689facb6bcb6f9eb786fs9&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Boom, git changes everything to match what they were at the time I took that snapshot. I can copy the bits I need onto my desktop, then make sure to put me back on where I just was&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$&amp;gt; git reset master&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This changes all my files to where I just was again, and I can go on with my life. So handy!&lt;/p&gt;
&lt;h2 id="what-else-can-i-do-"&gt;What else can I do?&lt;/h2&gt;
&lt;p&gt;Quite a lot, but all of that's covered by &lt;a href="https://git-scm.com/book/en/v2"&gt;the git book&lt;/a&gt;, and a lot of it is mostly irrelevant unless you also want to do remote syncing of your data. Still, good read if you really care about your data.&lt;/p&gt;
&lt;h2 id="what-if-the-command-line-is-too-unfamiliar-to-me-"&gt;What if the command line is too unfamiliar to me?&lt;/h2&gt;
&lt;p&gt;You can use the &lt;code&gt;git-gui&lt;/code&gt; command. This will ask you (if you "just run it") whether to create a new repository, or manage an existing one. I'm not going to explain how to use that, because  I never use it, but it can do all the things this post talked about.&lt;/p&gt;
&lt;h1 id="that-s-it-we-re-done-"&gt;That's it, we're done.&lt;/h1&gt;
&lt;p&gt;Go use version control. You &lt;em&gt;litearlly&lt;/em&gt; have no excuse not to. And if you have any questions or comments, you can either leave those over on github (see the link below this post) or just tweet at me &lt;a href="http://twitter.com/TheRealPomax"&gt;@TheRealPomax&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Version control your files, because you shouldn't be able to be your own enemy.&lt;/p&gt;
</description>
<category>Git</category>
<category>Version Control</category>
<link>http://pomax.github.io/#gh-weblog-1453231679399</link>
<guid>http://pomax.github.io/#gh-weblog-1453231679399</guid>
<pubDate>Tue, 19 Jan 2016 19:27:59 GMT</pubDate>
</item>
<item>
<title> React with LaTeX, without needing client-side Mathjax</title>
<description>&lt;p&gt;It's no secret that I like working with &lt;a href="https://facebook.github.io/react"&gt;React&lt;/a&gt;, and that I like &lt;a href="https://en.wikipedia.org/wiki/LaTeX"&gt;LaTeX&lt;/a&gt; for my maths, and that I like &lt;a href="https://mathjax.org"&gt;MathJax&lt;/a&gt; for my LaTeX on the web. What I don't like, though, is having to wait 20 seconds for a long article with lots of maths to load client-side, constantly changing the page dimensions as it does so. Especially if you're loading it mid-page and then MathJax kicks in and all the content keeps being pushed down. And again. And again, etc. etc.&lt;/p&gt;
&lt;p&gt;It's annoying for the user, and as the guy who runs a &lt;a href="http://pomax.github.io/bezierinfo"&gt;big article on BÃ©zier curves&lt;/a&gt;, with lots of maths, it's annoying to know I'm responsible for a bad experience. So, I'm rewriting that article so that it's easier to maintain, and loads a million times faster. One of the things that involves is taking MathJax out of the client-side experience, which means during LaTeX conversion server-side. Or really, "offline", because it should be a "generate once, then cache and use" instead of "having the server generate it all the time".&lt;/p&gt;
&lt;h2 id="react-and-webpack-and-babel-"&gt;React and Webpack (and Babel)&lt;/h2&gt;
&lt;p&gt;First off, a React codebase needs bundling, and generally also some &lt;a href="https://facebook.github.io/react/docs/jsx-in-depth.html"&gt;JSX&lt;/a&gt; transforming and &lt;a href="https://babeljs.io/docs/learn-es2015"&gt;ES2015+&lt;/a&gt; conversion, so the basis for my rewrite was a fairly simple dir layout with a fairly simple &lt;a href="https://webpack.github.io"&gt;Webpack&lt;/a&gt; config:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./
 |-&amp;lt;components&amp;gt;
 |-&amp;lt;images&amp;gt;
 |-&amp;lt;lib&amp;gt; 
 |-&amp;lt;stylesheets&amp;gt;
 | package.json
 | webpack.config.js
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the Webpack config doing the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var webpack = require('webpack');

// Hot Reload server when we're in dev mode, otherwise build it the normal way.
var entry = ['./components/App.jsx'];
if(!process.argv.indexOf("--prod")) { entry.push('webpack/hot/dev-server'); }

module.exports = {
  entry:  entry,
  output: {
    path: __dirname,
    filename: 'article.js'
  },
  module: {
    loaders: [
      { test: /\.(png|gif)$/, loader: "file?name=images/packed/[hash].[ext]" },
      { test: /\.less$/, loader: "style!css!less" },
      { test: /.jsx?$/, include: /components/, loaders: ['babel-loader']
      }
    ]
  },
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is a pretty standard setup, with webpack's &lt;a href="https://webpack.github.io/docs/hot-module-replacement-with-webpack.html"&gt;"hot reloading" server&lt;/a&gt; for dev work, and no server for production builds. Running Webpack for production will yield a file &lt;code&gt;article.js&lt;/code&gt; in the root, based on starting at the &lt;code&gt;component/App.jsx&lt;/code&gt; file, and then just bundling in every little requirement that has until we run out of things that need to be bundled in.&lt;/p&gt;
&lt;p&gt;You can see I'm using &lt;a href="http://babeljs.io"&gt;Babel&lt;/a&gt; for interpreting any js/jsx files (it takes care of JSX transforming and ES2015 syntax), as well as &lt;a href="http://lesscss.org"&gt;less&lt;/a&gt; for my CSS. There's also a dumb &lt;a href="https://www.npmjs.com/package/file-loader"&gt;"file-loader"&lt;/a&gt; which simply copies images into their own dir. Not always necessary, but useful when running the webpack dev server.&lt;/p&gt;
&lt;p&gt;The way I trigger either dev or prod runs is via &lt;a href="http://www.slideshare.net/k88hudson/advanced-frontend-automation-with-npm-scripts"&gt;npm scripts&lt;/a&gt;, with the &lt;code&gt;package.json&lt;/code&gt; using the following script block:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  ...
  "scripts": {
    "build": "webpack --prod",
    "start": "webpack-dev-server --progress --colors --hot --inline",
  },
  ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Two commands, a short &lt;code&gt;$&amp;gt; npm start&lt;/code&gt; for dev work, since that gets run all the time, and a special &lt;code&gt;$&amp;gt; npm run build&lt;/code&gt; for when the production bundle needs to be built. So far so good!&lt;/p&gt;
&lt;h2 id="adding-latex-to-react-components"&gt;Adding LaTeX to React components&lt;/h2&gt;
&lt;p&gt;One thing I hate when doing rewrites is "changing everything" to suit the technology. The article as it exists relies on LaTeX that takes the following form:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;p&amp;gt;\[
  f(x) = \sum^n_{k=0} \frac{n(n-k)}{k! + x} 
\]&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That's a pretty standard format if you use MathJax, or &lt;a href="https://github.com/Khan/KaTeX"&gt;KaTeX&lt;/a&gt;, and since I use a &lt;em&gt;lot&lt;/em&gt; of LaTeX, that format had to stay. And that's a bit of a problem, because LaTeX uses a lot of curly brackets. And React's JSX syntax treats curly brackets as templating delimiters.&lt;/p&gt;
&lt;p&gt;Something like this, for instance:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;p&amp;gt;\[
  \frac{percentage}{100}
\]&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;will cause the JSX transform step to go "uh, I don't know a variable &lt;code&gt;percentage&lt;/code&gt;, I can't convert this for you". Even though we don't want it converted. Too bad for us! However, there is a way out, and it's called a Webpack loader.&lt;/p&gt;
&lt;h2 id="webpack-and-mathjax-node"&gt;Webpack and mathjax-node&lt;/h2&gt;
&lt;p&gt;You may have noticed the part where I mentioned Webpack uses babel for JSX and ES2015 transforms. That means it rewrites the source code several times before handing it off for bundling, and so if we can convert those LaTeX blocks before anything else tries to interpret it, things should work pretty well!&lt;/p&gt;
&lt;p&gt;So, let us write a latex-loader for Webpack. In fact, I've already done the work there, so, let's look at that. First off, Webpack &lt;strong&gt;is weird&lt;/strong&gt; when it comes to loader order, and uses a &lt;a href="https://en.wikipedia.org/wiki/Stack_%28abstract_data_type%29"&gt;LIFO&lt;/a&gt; ordering. The last loader gets to run first. So:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;loaders: [
  ...
  {
    test: /.jsx?$/,
    include: /components/,
    loaders: [
      'babel-loader',
      __dirname + '/lib/latex-loader'
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With a corresponding &lt;code&gt;latex-loader.js&lt;/code&gt; in the &lt;code&gt;./lib&lt;/code&gt; dir:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var op = "\\[";
var ed = "\\]";

/**
 * Is there going to be anything to convert here?
 */
function hasLaTeX(input) {
  return input.indexOf(op) !== -1 &amp;amp;&amp;amp; input.indexOf(ed) !== -1;
}

/**
 * We look for MathJax/KaTeX style data, and convert it to something JSX-safe 
 */
function escapeBlockLaTeX(source) {
  // MAGIC HAPPENS HERE!
  return doTheMagic(source);
}

module.exports = function(source) {
  this.cacheable();
  if (!hasLaTeX(source)) return source;
  return escapeBlockLaTeX(source);
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That's the main gist of it, anyway. The loader's basically a single synchronous function that gets passed entire files as source string, and then expects a possible different string as replacement output.&lt;/p&gt;
&lt;p&gt;So, the approach is obvious: accept the source only if it has LaTeX that needs transforming (otherwise just hand the original source back as a thing we don't need to change), and then if we're still running, find all the LaTeX blocks, transform them to "something safe", and then return that modified source. Ideally, transform them using MathJax.&lt;/p&gt;
&lt;p&gt;As it turns out, MathJax has a server-side library available called &lt;a href="https://www.npmjs.com/package/mathjax-node"&gt;mathjax-node&lt;/a&gt;, which can be used to generate browser-agnostic SVG or MathML source, so that's perfect! It means we can do the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var mathjax = require("mathjax-node");

function escapeBlockLaTeX(source) {
  var from = 0, curr, term, newsource = "", latex;
  for(curr = source.indexOf(op, from);
      curr !== -1;
      from = term + ed.length, curr = source.indexOf(op, from))
  {
    // split out a block of LaTeX:
    newsource += source.substring(from, curr);
    term = source.indexOf(ed, from);
    if(term === -1) {
      // We only have ourselves to blame if we get here
      throw new Error("improperly closed LaTeX encountered!");
    }
    latex = source.substring(curr, term + ed.length);

    // convert this LaTeX code to SVG, which React can deal with just fine:
    var mathjaxed = mathjax.typeset(latex);

    // slot the SVG code in place of the LaTeX code
    newsource += mathjaxed;
  }
  return newsource + source.substring(from);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Except... we can't.&lt;/p&gt;
&lt;h2 id="webpack-mathjax-and-the-problem-of-sync-vs-async"&gt;Webpack, MathJax, and the problem of sync vs. async&lt;/h2&gt;
&lt;p&gt;You see, Webpack is a fully synchronous technology. A loader gets a file, transforms it, then passes it back to webpack, which hands it to the next loader, which transforms it, and so on. This is a fully synchronous process, and loaders simply get data, and "immediately" (give or take the time needed to modify that data) give something back.&lt;/p&gt;
&lt;p&gt;MathJax can't do that. It relies on quite a few asynchronous things (like font loads), and so where webpack has a function API much like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;module.exports = function webpackloader(input) {
  return formOutput(input);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;MathJax has a function API like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mathjax.typeset(input, function(result) {
  if(!result.errors) {
    doSomethingWith(result.svg);
  }
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That doesn't look too strange, &lt;a href="http://stackoverflow.com/questions/748175/asynchronous-vs-synchronous-execution-what-does-it-really-mean"&gt;but the timing is crucially different&lt;/a&gt;: when the Webpack loader runs, its function is entered, data is transformed, and it exits again. However, when the MathJax typesetter runs, the function call happens and then &lt;em&gt;immediately exits again&lt;/em&gt;, and at some point in the future the result handling function will run, and there is no way to "wait" for it to finish, because that's not a thing JavaScript can do.&lt;/p&gt;
&lt;p&gt;If only there was a way that we could turn the asynchronouse conversion process that MathJax requires, into a synchronous data transform as is required by Webpack...&lt;/p&gt;
&lt;h2 id="execsync-ing-our-way-to-success"&gt;execSync'ing our way to success&lt;/h2&gt;
&lt;p&gt;And in that wish we find the answer: make the conversion a command line utility, and then &lt;code&gt;exec&lt;/code&gt; that utility synchronously, using &lt;a href="https://nodejs.org"&gt;Node.js&lt;/a&gt;'s built in &lt;a href="https://nodejs.org/api/child_process.html#child_process_child_process_execsync_command_options"&gt;execSync&lt;/a&gt;, because the following will work brilliantly:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var execSync = require("child_process").execSync;

function escapeBlockLaTeX(source) {
  ...
  for(...) {
    // split out a block of LaTeX:
    latex = ...

    // convert all this!
    var mathjaxed = execSync("node tex2svg.js --latex " + latex);

    // slot the rewritten code back in
    newsource += mathjaxed;
  }
  ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We write a simple &lt;code&gt;tex2svg.js&lt;/code&gt; file that requires &lt;code&gt;mathjax-node&lt;/code&gt;, passes it the config options for conversion to SVG, read in the LaTeX as command line argument, and then spits out the conversion result on &lt;a href="https://en.wikipedia.org/wiki/Standard_streams"&gt;standard out&lt;/a&gt;, so that &lt;code&gt;execSync&lt;/code&gt; treats it as its function return value.&lt;/p&gt;
&lt;p&gt;But here's where things get tricky. Writing a command line utility that does the MathJax conversion requires a little work, because the command line is tricky, and LaTeX contains all kinds of characters that can do things in shell land. Slashes and ampersands abound, and those are kind of active symbols,  so we need to be a little smarter:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// convert all this... smarter!
var base64 = new Buffer(latex).toString("base64");
var mathjaxed = execSync("node tex2svg.js --base64 " + base64);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then we just need to make sure that the MathJax script unpacks the passed data from &lt;a href="https://en.wikipedia.org/wiki/Base64"&gt;base 64 format&lt;/a&gt; to plain string format before converting, and we're good!&lt;/p&gt;
&lt;p&gt;But not quite: this is not exactly a cheap thing to do. Firing up an instance of node and loading &lt;code&gt;mathjax-node&lt;/code&gt; takes time. Not enough to notice if you only do it once, but if you need to run this lots of times, a second each time adds up to having to wait minutes for this building to happen. Every time you want to run the dev server.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;That is unacceptable.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So, let's add in some caching: instead of having the MathJax script do the conversion for us, and then spit out the SVG code, we make it do the conversion but then write the SVG code to file, in the images dir.&lt;/p&gt;
&lt;p&gt;And because we don't want the build process to do more work than necessary, we make the filenames predictable, based on the LaTeX that needs to be converted: we compute the &lt;a href="https://en.wikipedia.org/wiki/SHA-1"&gt;sha1 digest&lt;/a&gt; of the LaTeX that needs converting, and only if we don't see a file called &lt;code&gt;&amp;lt;hash&amp;gt;.svg&lt;/code&gt; in the images dir do we do our conversion:  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var sha1 = require("sha1");

function escapeBlockLaTeX(source) {
  ...
  for(...) {
    latex = ...;

    // Get the digest for the latex - any subsequent checks for the same block
    // of LaTeX will yield the exact same digest, which is handy!
    var hash = sha1.hash(latex);

    // Whether the SVG for this LaTeX already exists or not, we already know
    // the filename it's going to have, so we can prebuild the JSX we need:  
    var imgHTML = '&amp;lt;img src="' + hash + '.svg" className="LaTeX SVG"/&amp;gt;';

    // Then: do we need to generate this image first? If so, execSync,
    // otherwise we do absolutely nothing because we're already done!  
    if (!imageExists(hash)) {
      var base64 = new Buffer(latex).toString("base64");
      execSync("node tex2svg.js --hash " + hash +" --base64 " + base64);
    }

    newsource += imgHTML;
  }
  return newsource;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And that, as they say, is that!&lt;/p&gt;
&lt;h2 id="boom-"&gt;Boom.&lt;/h2&gt;
&lt;p&gt;Using this latex-loader in conjunction with a file writing conversion utility script, we now have a &lt;em&gt;synchronous&lt;/em&gt; MathJax conversion going on, despite MathJax itself being an inherently asynchronous processor, and we completely bypass any strangeness that might normally pop up if you tried to mix LaTeX code and JSX syntax, with the benefit of files that can be cached, so that the browser doesn't need to redownload them everytime the article gets loaded in a browser.&lt;/p&gt;
&lt;p&gt;Responsiveness increase: x1 million. Goal reached.&lt;/p&gt;
&lt;p&gt;Instead of every individual user needing to wait for MathJax to do typesetting, the only person waiting for MathJax now is me, and only for "new" LaTeX blocks during the build step. &lt;em&gt;As it should be&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I can add sections one at a time, and every time I run the build step, only genuinely new LaTeX will need to get converted. LaTeX that got processed during a previous run already wrote files to disk, so the latex-loader just bypasses the conversion process entirely for those LaTeX blocks, and so the build really only does exactly as much work as it needs to do to get the data transformed.&lt;/p&gt;
&lt;p&gt;Needless to say, I am chuffed to bits about this, and if you have any questions about the process, feel free to reach out to me &lt;a href="https://twitter.com/TheRealPomax"&gt;on twitter&lt;/a&gt; or &lt;a href="https://github.com/Pomax/BezierInfo-2/issues"&gt;on github&lt;/a&gt;, and I'll be happy to talk about it more.&lt;/p&gt;
</description>
<category>React</category>
<category>LaTeX</category>
<category>MathJax</category>
<category>Webpack</category>
<link>http://pomax.github.io/#gh-weblog-1451617530567</link>
<guid>http://pomax.github.io/#gh-weblog-1451617530567</guid>
<pubDate>Fri, 01 Jan 2016 03:05:30 GMT</pubDate>
</item>
<item>
<title> Developing Open Source Software</title>
<description>&lt;p&gt;I want to take a little bit of time to explain how I work on Open Source, both privately and as part of my job as a Software Engineer at the Mozilla Foundation. Not because it's wildly different from how everyone else does it, but because it's probably the same as how the vast majority works on Open Source, which means very few people bother to explain the processes involved.&lt;/p&gt;
&lt;p&gt;There are two different kinds of "working on open source", depending on whether the code is a collaboration or just a simple one-person project, so let's look at both.&lt;/p&gt;
&lt;h2 id="-i-m-making-a-thing-"&gt;&lt;em&gt;"I'm making a thing!"&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;If you're making a thing, the basic rule is "anything goes": you're the only one you're inconveniencing by taking shortcuts, and often that's fine. However, if you're starting a project that you think might at some point gain contributors (say, you're making a thing that you hope becomes popular), there are a few things you can do to make sure that when your project does go from "one dev" to "a team", the transition is smooth:&lt;/p&gt;
&lt;h3 id="file-issues-before-fixing-them"&gt;File issues before fixing them&lt;/h3&gt;
&lt;p&gt;Not only is it a handy If you file the issues you know about as a kind of to-do list to walk through, but you might be surprised to find someone actually fixing an issue you filed before you get to it, once your project gets even a little exposure.&lt;/p&gt;
&lt;h3 id="work-in-branches-"&gt;Work in branches.&lt;/h3&gt;
&lt;p&gt;There will be an initial "I just need to get this code written" period where you're pushing to master: awesome, go for it. However, once you reach what might turn into a 1.0 with a bit more code, start getting in the habit of treating your master branch as off limits, and working in branches that you merge into master instead. This makes it easier for contributors to do the same.&lt;/p&gt;
&lt;h3 id="document-document-document-"&gt;Document, document, document.&lt;/h3&gt;
&lt;p&gt;You're not actually working on your code alone: you're collaborating with your future self, and future self has no idea what you're thinking right now while you're writing your code: document your choices, explain complex bits of code and whatever you do, explain hacks and bodges! Clever as they might be today, 2 months from now they might be so clever you actually need to spend your own time on them to figure out why they even work the way they do. Help future-you out: write documentation.&lt;/p&gt;
&lt;p&gt;And that doesn't need to be wikis or long readmes, it can just be code comments: as long as knowledge you need to understand changes you're making right now isn't lost, you're being awesome. &lt;/p&gt;
&lt;h2 id="-we-re-making-a-thing-"&gt;&lt;em&gt;We're making a thing.&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;While you're fairly free to do what you want to do on your own, for collaborative projects, there is really only one way to work in a way that's not going to break down. For anything that needs to be done, follow the three F's:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;File it&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fix it&lt;/strong&gt;, and&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Follow up&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="1-file-it-"&gt;1) File it!&lt;/h3&gt;
&lt;p&gt;If you're going to work on something, make sure it's a known issue. Code changes without an issue that explain why the changes were necessary in the first place are mystery changes, and mysteries in a collaborative effort are bad.&lt;/p&gt;
&lt;p&gt;However, that doesn't mean the changes aren't necessary, so: always, &lt;strong&gt;always&lt;/strong&gt; make sure there's a ticket, or issue, or bug report, associated with the changes you're making, so that your code changes can say "this fixes/addresses ticket/issue/bug so-and-so". Sometimes those tickets/issues/bug reports already exist and you can simply refer to them, but sometimes they don't: &lt;strong&gt;file it before submitting your code changes&lt;/strong&gt;, so that you can refer to that newly filed ticket.&lt;/p&gt;
&lt;p&gt;It's okay to already have the code in place that addresses an issue you haven't filed yet, just make sure that by the time you submit your changes, there is one.&lt;/p&gt;
&lt;p&gt;Collaboration relies on communication. If people change the code without tying it to the list of "these are issues we need to address", then there is no way to track changes in the codebase. Generating a changelog based on closed issues is often quite easy, but if there are no issues that got closed/resolved due to changes getting accepted into the code base, then you're asking people to work on code that potentially no one can explain (because the person who contributed it may have left already. If you can even track who submitted the change at all).&lt;/p&gt;
&lt;p&gt;Also, &lt;strong&gt;file individual issues&lt;/strong&gt;. The best code bases are ones where each thing that needs to be done is filed separately, and fixed separately, because it's much easier to work on as a team (small tasks make for rapid progress), and it makes it easy to track complex tasks: if you need to implement a user profile system, and that requires a login system, a user database, and user facing UI, then if someone files "implement a user profile system", the very first thing that should happen is chopping that issue up into several smaller issues. It might sound anal, but you're working in a team, and many hands make light work: the smaller you can chop up an issue, the easier it becomes to resolve the bigger task.&lt;/p&gt;
&lt;h3 id="2-fix-it-"&gt;2) Fix it...&lt;/h3&gt;
&lt;p&gt;Crazy as it may sound: never start fixing things by writing code. First ask: "Has someone else already written the code and can I just plug that in?". If they have: just use that. You're still probably going to need a little bit of code to do the "plugging it in" part, but little bits of code are easy to maintain, and it means you're not responsible for maintaining lots of code.&lt;/p&gt;
&lt;p&gt;Conversely, if there is no code out there that already does what you need to do, ask yourself: "Can I write this as a standalone utility, and then plug &lt;em&gt;that&lt;/em&gt; in?". Because if you can, that's worth doing. If you need to solve a problem and there's no solution out there, you're probably solving a problem that other people are also having: it's worth making that solution available.&lt;/p&gt;
&lt;p&gt;Of course, there will be plenty of issues that can only be addressed by writing real, project-relevant, code, and for those occasions there are three things to keep in mind:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;commit early&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;commit often&lt;/strong&gt;, and&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;communicate with your team&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="commit-early"&gt;Commit early&lt;/h4&gt;
&lt;p&gt;If you're working on code changes, push up your changes as soon as you have "something" going. &lt;strong&gt;Especially if it's not done yet&lt;/strong&gt;. Don't wait until "it's done", because you have no idea when that will be: form a commit and push it up once you have the basic stubs in place, for instance, before you start working out the code in full.&lt;/p&gt;
&lt;p&gt;This lets other people that work with you see what you're working on, and lets them catch things early that would cost a lot of time to fix later on. &lt;/p&gt;
&lt;h4 id="commit-often"&gt;Commit often&lt;/h4&gt;
&lt;p&gt;Some code changes are one liners or a simple function renaming, but many are not: don't wait until you're done to push up your changes. Any time you write some code and test it, and it passes, that's a moment to form a commit, push it up, and then keep going.&lt;/p&gt;
&lt;p&gt;If a computer dies (and if you work in a team, that will happen surprisingly often) or someone unexpectedly becomes unavailable for a few days (again, happens more often than you might think), there is no loss of work &lt;strong&gt;for the team&lt;/strong&gt;. The team as a whole can pick up where you as a person left off in these circumstances, and if you don't commit often, they'll potentially have to reinvent changes you had already written.&lt;/p&gt;
&lt;p&gt;It's also much easier to rebase your code if they're small incremental commits when the master code base changes. For instance, a dependency got updated, which caused some functions to use that dependency's new API calls; that is much easier to deal with if it just requires you to change the small commit that touched a file for which that was the case than if you have one massive commit.&lt;/p&gt;
&lt;p&gt;Additionally, the more often you commit, the earlier possible bugs can be found; the earlier bugs are found, the less work it is to fix them, because not a lot of things will trigger them yet.&lt;/p&gt;
&lt;h4 id="communicate-with-your-team"&gt;Communicate with your team&lt;/h4&gt;
&lt;p&gt;If you're working on anything even moderately sized: start talking about your code with team members early. Don't ask them to review only all the way at the end if your changes involve new code or new approaches; run it by someone so that even if you're the only one that'll end up writing code, you're &lt;em&gt;not&lt;/em&gt; the only one who knows what decisions were made while the code was being written.&lt;/p&gt;
&lt;p&gt;Also, remember to ask questions in the open. You might end up with blocking questions that need an answer before you can continue your work, and while it's tempting to try to find someone to get it answered in real-time, &lt;strong&gt;file it first&lt;/strong&gt;, so that the entire team can see it. Then you can find someone to real-time answer it and capture the answer in the filed issue, so that the entire team can be aware of the question having come up, and the answer that was agreed on.&lt;/p&gt;
&lt;h4 id="corrolary-know-when-to-split-your-work-"&gt;Corrolary: know when to split your work.&lt;/h4&gt;
&lt;p&gt;Some issues reveal problems in other parts of the project, and you might be tempted to fix those as part of your changes. I know it's tempting, but &lt;strong&gt;don't&lt;/strong&gt;, because you're not actually helping the team that way. Instead: file it, fix it, and follow up.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Step away from the current code when you reach a good break point (and that could be immediately, if the thing you found is blocking you),&lt;/li&gt;
&lt;li&gt;File the issue as a new issue,&lt;/li&gt;
&lt;li&gt;If it's blocking you:&lt;ol&gt;
&lt;li&gt;Fix it first,&lt;/li&gt;
&lt;li&gt;Schedule follow up&lt;/li&gt;
&lt;li&gt;Rebase your code on the fix, so you're unblocked&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Now you can come back to the code you were already working on.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You'll note that in step 3 the advice is to work on it immediately only if it's actually blocking you: this is important. You're working in a team, and someone else might have a free moment to work on the thing you just discovered, while you keep working on your own changes.&lt;/p&gt;
&lt;h3 id="3-run-through-the-follow-up-"&gt;3) Run through the follow-up.&lt;/h3&gt;
&lt;p&gt;You've worked on code changes, you committed early, and often, and your "patch" now consists of 12 commits and two observations about future work: it's time for follow-up.&lt;/p&gt;
&lt;h4 id="clean-up-your-code"&gt;Clean up your code&lt;/h4&gt;
&lt;p&gt;If your changes work using 12 commits, then your changes work, and it's time to squash those 12 commits into a single commit so it can be landed into the codebase without all the steps that got you there. Even if there is no requirement to squash your code before landing, changelog generation, revision control, and rollbacks are all much nicer if patches land as single commits.&lt;/p&gt;
&lt;p&gt;Also, if there are any unnecessary comments or logs/prints in your code, now's the time to get rid of those, and of course, now is also the time to make sure that any missing documentation either gets added, or gets filed as "document XYZ", to be worked on immediately after landing your changes, rather than anything else, which brings us to...&lt;/p&gt;
&lt;h4 id="file-anything-you-found-but-didn-t-fix-"&gt;File anything you found, but didn't fix.&lt;/h4&gt;
&lt;p&gt;While you were working on your changes, you may have thought of things that might need addressing outside of the changes you made: &lt;strong&gt;file those&lt;/strong&gt;. It is important to capture those observations in a way that the entire team can see them.&lt;/p&gt;
&lt;h4 id="talk-to-your-team"&gt;Talk to your team&lt;/h4&gt;
&lt;p&gt;Finally, follow up with people, too. Let the people who need to know about your changes know about your changes - ask them to review you patch, explain your work to them where needed, if there is testing involved, make sure they understand what needs to be done, and generally make sure at least two people agree these changes are good to go (including yourself). That communication doesn't need to happen in person, the issue tracker you use might facilitate this kind of follow up, but always collaborate on the landing, even if the code works. There might be last minute changes or decisions that you were not aware of that someone else might: good to discover that before the changes are merged in!&lt;/p&gt;
&lt;h2 id="that-s-pretty-much-it"&gt;That's pretty much it&lt;/h2&gt;
&lt;p&gt;There's a fair amount of finer detail and variation that fits into the "file it, fix it, follow up" process, but stick to that order and you're on the path of a sustainable development cycle.&lt;/p&gt;
&lt;p&gt;Most of this is probably obvious to most people, but that just makes it all the more important to get it written down, because someone's going to be a bit bewildered and they'll need a blog post to get them on track =)&lt;/p&gt;
</description>
<category>Open source</category>
<category>Development</category>
<category>Process</category>
<category>Mozilla</category>
<link>http://pomax.github.io/#gh-weblog-1450207129290</link>
<guid>http://pomax.github.io/#gh-weblog-1450207129290</guid>
<pubDate>Tue, 15 Dec 2015 19:18:49 GMT</pubDate>
</item>
<item>
<title> OpenType: let's learn how modern fonts actually work</title>
<description>&lt;p&gt;In a previous post &lt;a href="/1449438115186"&gt;I talked about the distinction between "TTF" and "OTF" fonts&lt;/a&gt;, and the fact that they're actually both just OpenType fonts. I explained how the difference between TTF and OTF is only which outline language is used, with everything else being the same between the two types of Opentype font, so in this post I'd like to talk about some of the bits that all OpenType fonts have. There are actually quite a lot of things, so this will not be the last post on the subject, but let's just cover as much as we can and see what that leaves.&lt;/p&gt;
&lt;p&gt;Let's start with something that might sound like it can't possibly be true:&lt;/p&gt;
&lt;h2 id="fonts-don-t-contain-letters-"&gt;Fonts don't contain letters.&lt;/h2&gt;
&lt;p&gt;I know this sounds a bit weird for a technology that is supposed to be used to draw letters, but it's important to get this out of the way first: fonts don't know anything about "letters". Instead, they know about character codes, and glyphs. Character codes are simply numbers that the computer sees when you type, when it reads a text file, etc. and glyphs are anything in the font "that can be drawn". A font is a collection of inherently meaningless pictures, linked to character codes to give them meaning.&lt;/p&gt;
&lt;h3 id="the-problem-with-defining-letters-"&gt;The problem with defining "letters"&lt;/h3&gt;
&lt;p&gt;The reason fonts contain character codes and glyphs, rather than "letters" is that letters are a very restricted class of things we write. For instance, clearly the "letters" a through z are letters; this is true by definition. But are numbers letters? We can say that Fonts contain numbers and letters, but then what about symbols? Okay, fonts contain numbers, letters, and symbols. Clearly we're done. But what about CJK languages? Their writing systems don't use "letters": Korean has syllables, instead, Chinese has logograms, and Japanese uses both. So now things are getting very tricky. But let's make it even more fun: let's look at different kinds of the same letter. In English, the 'a' and the 'A' are both the same letter, as well as different letters. If you had to group the elements of a set "a,a,A,a,a,A,A,b,A,b,b,a,B,B,B", you would probably group them as a's in one pile, and b's in another. But if you had to group a full mixture of the alphabet in upper and lowercase, you'd probably sort them according to case. Are they the same letter or different letters? What about Arabic, in which each letter has four possible shapes depending on where in a word it's used (a letter will look different depending on whether it's on its own, or at the start of, middle of, or end of a word). What about those, are those all different letters, or the same one?&lt;/p&gt;
&lt;p&gt;So in order to get around this problem, fonts don't contain letters. They contain &lt;a href="https://en.wikipedia.org/wiki/Glyph"&gt;glyphs&lt;/a&gt;: anything that you can draw an outline for can be made a glyph, so that in a font: yes, all those different forms of the same thing are different things, and it's up to the character mapping and substitution rules specified in the Opentype font to determine which glyph should be used when.&lt;/p&gt;
&lt;h3 id="character-code-sets"&gt;Character code sets&lt;/h3&gt;
&lt;p&gt;So where do the character mappings come from? How many are there? Which are "the best"?&lt;/p&gt;
&lt;p&gt;For convenience, I'm going to ignore a &lt;em&gt;lot&lt;/em&gt; of history, mostly because you can write full chapters on the history of character mappings, and we'd still not get to where I want to get in this post, so: lots of different people and organisations have coined lots of different character mappings throughout the history of computing, and of those, I want to focus on two major ones: ASCII, and Unicode.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/ASCII"&gt;ASCII&lt;/a&gt; is probably the oldest, still widely used, standard, and it was invented to capture the symbols used in American computing, using 7 bits. Because back in the day, there weren't necessarily 8 bits to a byte, sometimes you have 7, or 6, or some other value that we now think of as weirdly "not eight". Anyway, ASCII uses 7 bits, and so there are 128 possible codes available: 0 through 127. The first 32 codes are "control" codes, not so much related to typing things as controlling the computer: escape, backspace, tabulation, line feed, data acknowledgement, things that control what the computer will do. After that are the numbers, letters, and symbols that were commonly (and a few uncommonly) used in American computing environments, and the very last code is the "delete" code.&lt;/p&gt;
&lt;p&gt;Of course, at the same time the rest of the world was inventing tons of other encodings because America wasn't the only country in the world using computers, and as the world became more and more connected, the more we had problems around trying to read text written by someone who wasn't using the same encoding, as well as needing way more than just 128 "spots" to capture all the different things necessary for each language, let alone "all languages".&lt;/p&gt;
&lt;p&gt;And that's where &lt;a href="https://en.wikipedia.org/wiki/Unicode"&gt;Unicode&lt;/a&gt; comes in: Unicode was, and remains, our best effort to fit all writing systems in this world into a single character mapping. As you can imagine, that mapping is huge: over 120,000 codes at this point in history (in June 2015, the Unicode standard v8 was released). But: the standard is public, it's stable (meaning that it's never going to fix historical mistakes like two different codes that point to the same character, but that no one noticed before accepting the code into the standard), and it takes a fairly long time to get new codes assigned specifically to make sure that standard doesn't "just grow" as we add more and more languages into it, but actually has some internal logic that computer scientists, programmers, etc. can rely on.&lt;/p&gt;
&lt;p&gt;The one thing that made switching to Unicode even possible, was that the first 128 codes in Unicode are, in fact, the ASCII codes, which made it possible to switch from ASCII to Unicode with virtually no effort. ASCII data, in an 8 bit world, is automatically data that matches the Unicode mappings, "encoded using the UTF-8 scheme".&lt;/p&gt;
&lt;h3 id="byte-encodings"&gt;Byte encodings&lt;/h3&gt;
&lt;p&gt;If you have a standard that contains way more numbers than fit in 8 bits, you need an extra step to turn possibly huge numbers into sequences of bits. Where ASCII is both the character code set and the encoding, Unicode needs a bit more work: it is only the character code set, and in order to write those codes as bytes on a disk, it has various "byte encoding" schemes available. All of these encode "Unicode data", but byte patterns on the disk can look radically different.&lt;/p&gt;
&lt;p&gt;The two common encodings for Unicode are things you've probably heard of, even if you don't know what they are exactly: UTF-8, or UTF-16. For details on both, wikipedia is a great source of information, so I will just summarise them here.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/UTF-16"&gt;UTF-16&lt;/a&gt; simply "tried" to capture every code using 16 bits, and then when there were so many codes that it became obvious that 16 bits would not be enough, a special few codes were reserved for "if you see this code, it's actually not a character mapping itself, but has to be combined with the &lt;em&gt;next&lt;/em&gt; 16 bits to form one of the higher numbers that don't fit in 16 bits".&lt;/p&gt;
&lt;p&gt;From this description, you'd imagine that &lt;a href="https://en.wikipedia.org/wiki/UTF-8"&gt;UTF-8&lt;/a&gt; does something similar, and it totally does, except it's generally far more efficient than UTF-16 in how it does it; UTF-8 is a variable byte encoding, with marker bits to say how many bytes are used, and whether a byte is a "start" byte or a follow-up byte. It matches ASCII byte-for-byte by starting with the bit 0 ("there are no next bytes") and then the 7 bit ASCII value. For any value larger than 128, needing more than 1 byte, the first byte starts as 1,1,0 if there are going to be 2 bytes used, 1,1,1,0 for three, 1,1,1,1,0 for four, etc. Any subsequent byte starts with 1,0 (so if you pick a random spot in a UTF-8 stream, and you see a byte that starts as 1,0 you know you need to move forward or backward a little so you're not in the middle of a character's code representation).&lt;/p&gt;
&lt;h3 id="from-code-sets-to-glyphs"&gt;from code sets to glyphs&lt;/h3&gt;
&lt;p&gt;So on the conceptual side, we have "things you can write", which we capture as glyphs in a font, and a character mapping that assigns each of those things a number, but then we still have a problem: fonts don't have to implement every possible character, so if we look at the character mappings that are actually &lt;em&gt;used&lt;/em&gt; in a font, there might be lots of disjointed sets of supported, and not supported mappings.&lt;/p&gt;
&lt;p&gt;Fonts, on the other hand, are relatively efficient in how they store glyphs: they use arrays. The first glyph is in spot 0, the second glyph is in spot 1, the third in spot 2, and so forth: they are a stored in a list without gaps, and their ordering in that list is not related to any encoding or character mapping. It's just a list of pictures with ids derived directly from their position in the list.&lt;/p&gt;
&lt;p&gt;So even if we have our list of glyphs, and we know which character mapping our font will work with, and we know which parts of that mapping the font will support, we still need one more step to make sure we can look up with character code maps to which position in the font's list of glyphs.&lt;/p&gt;
&lt;h3 id="-internal-glyphs"&gt;"internal" glyphs&lt;/h3&gt;
&lt;p&gt;Finally, there can also be glyphs that don't map to character codes. This sounds a bit odd, because how would you ever see them, but glyphs don't need to specify all the outline data in a giant wad of instructions: they can also contain references to other glyphs. For instance, the Japanese character æ¾ (pine tree) and æ¿ (persimmon) have the same "drawing" on the left side. We can store that particular outline as an internal glyph, with its own glyph id, and then form those two characters by starting each off as saying "place the glyph at id ... on the left" before explicitly specifying the outlines for the rest of the glyph.&lt;/p&gt;
&lt;p&gt;As such, a font kind of &lt;em&gt;can&lt;/em&gt; contain gaps in the list of glyphs, not by having "nothing" in the list in some spots, but by having glyphs that don't have a mapping to any character code. Things can get really tricky!&lt;/p&gt;
&lt;h2 id="the-cmap-table"&gt;The CMAP Table&lt;/h2&gt;
&lt;p&gt;At this point you might think: "...but there are so many encodings and character mappings and no rules on how to order glyphs in that list, there must be millions of ways for that final mapping to look!" And you're not wrong. There really are an incredible number of "character code to font-internal glyph id" mappings that could exist, and so OpenType comes with not just one, but several different ways to set up a "character to glyph id" mapping, based on a few things like "does the font implement one, or multiple, sets of character codes", "can there be gaps in the sets or not", "are any of the sets not commonly implemented sets", etc. By answering these questions, you can find the best charcode to id mapping for what your font will support, and then based on that you can follow a small number of rules around how to order the glyphs in the list of glyphs so that everything will work efficiently.&lt;/p&gt;
&lt;p&gt;The thing that makes this work in OpenType fonts is called the &lt;a href="https://www.microsoft.com/typography/otspec/cmap.htm"&gt;&lt;code&gt;CMAP&lt;/code&gt;&lt;/a&gt; table, and if you're still thinking "wait, that sounds like still not enough to capture all those possibilities", you're still right, and OpenType lets you specify &lt;em&gt;multiple&lt;/em&gt; CMAP subtables, which can all be different, to efficiently cover the entire range of supported characters in your font.&lt;/p&gt;
&lt;p&gt;While you might think that the pictures inside the font are the most important part of a font, in terms of how fonts &lt;em&gt;work&lt;/em&gt;, the CMAP is the absolutely most important part: if the outlines are missing, but we have a CMAP, at least the CMAP can tell us there are no pictures to work with, and if any of the OpenType metadata is missing, we might be rendering the text in a really weird way, but without a CMAP we don't even know what characters a font supports, or how to even get to any of the pictures we need to render text. Without a CMAP, a font is just a useless binary file.&lt;/p&gt;
&lt;p&gt;(And yes, historically there have been font formats that actually had outline data in one file, being the 'useless binary file', and a separate cmap file that you could load to give meaning to the 'useless data')&lt;/p&gt;
&lt;h2 id="substitutions"&gt;Substitutions&lt;/h2&gt;
&lt;p&gt;Finally, we need one more thing to deal with issues around "which glyph do we even use?" such as what we saw for Arabic: one letter, but depending on where in a word it is, it has to look different. Or closer to English: ligatures, where typing an 'f' followed by an 'i' tends to generate some shape fi that looks different, and is in fact a different glyph, from the separate letters.&lt;/p&gt;
&lt;p&gt;This is called "substitution", and is handled by a table called the &lt;a href="https://www.microsoft.com/typography/otspec/gsub.htm"&gt;&lt;code&gt;GSUB&lt;/code&gt;&lt;/a&gt; table. It allows various kinds of substitutions, with rules that can be different depending on the language or script the font has to style: substitution rules for English may not need to apply in Vietnamese, for instance. In order to deal with all kinds of substitutions, the GSUB table is &lt;a href="https://www.microsoft.com/typography/otspec/chapter2.htm"&gt;split up into several sections&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;scripts, which say which "language" the text is in&lt;/li&gt;
&lt;li&gt;features, which control when substitutions kick in (such as common ligatures, historical number forms, etc)&lt;/li&gt;
&lt;li&gt;lookups, which are the actual "A becomes B" rules.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To get a substitution set up, you need a lookup (to say which actual substitution has to happen), tied to a feature (which gives the typographical context for the lookup), tied to a script (which gives the linguistic context for the feature). All of these are many-to-many, so one feature could be used by multiple scripts, and one script can use multiple features (and then the same for features and lookup relations).&lt;/p&gt;
&lt;p&gt;Substitution lookups also come in various forms, so that there are special structions for one-for-one substitutions (like turning every full stop into a Japanese sentence end marker), many-for-one (like word to icon substitution), initial, medial, and final substitutions (for languages like Arabic) and the rather complicated "contextual substitution" which lets you define patterns in the text that have to be true for the substitution to kick in.&lt;/p&gt;
&lt;h2 id="wrapping-up"&gt;Wrapping up&lt;/h2&gt;
&lt;p&gt;While it's tempting to argue about TTF vs OTF, the thing that really drives a font is the CMAP. Hopefully you now understand the core concept for modern OpenType fonts a bit better, understanding how a font knows which characters it supports, and how it it maps what you type to what you see.&lt;/p&gt;
&lt;p&gt;In a next post I'll cover some more typographical concepts like kerning and positioning, as well as some of the finer nuances between TrueType and Type2 outlines, which work together with the pure OpenType data about those things.&lt;/p&gt;
&lt;p&gt;And if you have questions, or comments, do let me know by clicking the comment link below.&lt;/p&gt;
</description>
<category>Fonts</category>
<category>OpenType</category>
<category>CMAP</category>
<category>GSUB</category>
<category>TTF</category>
<category>OTF</category>
<link>http://pomax.github.io/#gh-weblog-1449777175633</link>
<guid>http://pomax.github.io/#gh-weblog-1449777175633</guid>
<pubDate>Thu, 10 Dec 2015 19:52:55 GMT</pubDate>
</item>
<item>
<title> OpenType: what's the difference between TTF and OTF??</title>
<description>&lt;p&gt;This is going to be a multiparter, because I've been trying to write this as a single long read and it's just not working. So as the first part in part of an OpenType series: ttf and otf... what's the difference?&lt;/p&gt;
&lt;h2 id="first-it-s-all-opentype"&gt;First, it's all OpenType&lt;/h2&gt;
&lt;p&gt;One thing that most people don't know is that both TTF and OTF font are &lt;a href="https://www.microsoft.com/typography/otspec/"&gt;OpenType fonts&lt;/a&gt;. OpenType is a binary format, with an open specification (i.e. it's free to implement codecs for, and you can sign up for the opentype mailing list and influence future versions), that contains outline data (for drawing letters), tons of metadata used for things ranging from typesetting to hardware memory management, and language-specific typesetting rules like contextual substitutions and positioning. &lt;/p&gt;
&lt;p&gt;When people talk about "TTF" or "OTF" what they really mean is "files that end in &lt;code&gt;.ttf&lt;/code&gt; and &lt;code&gt;.otf&lt;/code&gt;", and those are two kinds of OpenType font: fonts ending in &lt;code&gt;.ttf&lt;/code&gt; are generally OpenType fonts that use the glyf/loca data blocks, with &lt;a href="https://www.microsoft.com/en-us/Typography/SpecificationsOverview.aspx"&gt;"TrueType"&lt;/a&gt; outlines, whereas fonts ending in &lt;code&gt;.otf&lt;/code&gt; are OpenType fonts that use a &lt;a href="https://partners.adobe.com/public/developer/en/font/5176.CFF.pdf"&gt;CFF data block&lt;/a&gt;, with &lt;a href="https://partners.adobe.com/public/developer/en/font/5177.Type2.pdf"&gt;"Type2"&lt;/a&gt; outlines. So the difference is in the outline language used. Everything else is the same, and there's a &lt;em&gt;lot&lt;/em&gt; of "everything else" in an OpenType font.&lt;/p&gt;
&lt;p&gt;We're not going to look at all the fine differences between the two in this post, but let's look at the ones that are easy to talk about and already make a big difference:&lt;/p&gt;
&lt;h3 id="truetype-tiny-simple-and-hardcoded-hinting"&gt;TrueType - tiny, simple, and hardcoded hinting&lt;/h3&gt;
&lt;p&gt;TrueType outlines are incredibly straight forward: you get lines and &lt;a href="http://pomax.github.io/bezierinfo/#introduction"&gt;quadratic curves&lt;/a&gt;, and that's pretty much it. It's really easy to define shapes in, but the curves are "too" simple so you need quite a few of them. If you have decent design tool, that's mostly irrelevant, and the only thing you'll notice is that an OpenType font that uses TrueType outlines tends to be bigger than an OpenType font with Type2 outlines for the same shapes.&lt;/p&gt;
&lt;p&gt;The other way in which TrueType differs is in how &lt;a href="https://www.typotheque.com/articles/hinting"&gt;"hinting"&lt;/a&gt; works. Hinting is a mechanism to tell font engines "if you need to scale this outline down to fit in the font size we need, and that leads to weird sub pixel positioning, here's how you should resolve that:..." When using TrueType, the hinting is explicit: all the information is stored in the TrueType data, so a font engine can be "dumb" about hinting and simply do what the font tells it to. That makes TrueType, again, a little bigger compared to Type2, but taken together with the simplicity of the language means it's really easy for people to write parsers that do the right thing. Not a lot of instructions, and the hinting is in-font.&lt;/p&gt;
&lt;p&gt;(Although even then, hinting can go &lt;a href="http://www.rastertragedy.com/"&gt;terribly wrong&lt;/a&gt;, because it's an incredibly hard subject)&lt;/p&gt;
&lt;h3 id="type2-rich-complicated-and-only-hinted-"&gt;Type2 - rich, complicated, and "only" hinted.&lt;/h3&gt;
&lt;p&gt;On the other hand, the Type2 language is super rich, with lots of nuanced outline operations possible (including some 'if humans can tell this is gently curve, curve it, otherwise make this a flat line" instructions!), as well as supporting a small programming language that lets you do some amazing things... if the font engine that's rendering the font supports them. Because most of them don't: Type2 supports lines and cubic curves, and these are generally supported by font engines, but they also support more esoteric operations that a lot of font engines simply don't bother to support. That is unfortunate, and hopefully that will change as time goes on, but right now that's how it is.&lt;/p&gt;
&lt;p&gt;To make matters worse, the hinting in a Type2 outline is really "just hints". Type2 outlines can mark certain edges and points as needing to line up in some way, but it is up to the font engine to make sure that "lining up" happens sensibly, and (again because this is not a trivial task) a lot of font engines just ... don't bother.&lt;/p&gt;
&lt;p&gt;This leads people who are used to working with software that comes with a simple, or incomplete, font engine to claim that TTF is better than OTF because they look better, even though they don't: it's just the font engine not being good enough to deal with the space-optimised Type2 outline language, rather than the simplistic but "everything up front" TrueType outline language.&lt;/p&gt;
&lt;h2 id="-which-should-i-use-"&gt;"Which should I use?"&lt;/h2&gt;
&lt;p&gt;The real question tends to be which format you should use. If you're  a typeface designer, or a font engineer, I don't have to tell you which is to use, you already know the answer based on what you need to make, but if you're a font &lt;strong&gt;user&lt;/strong&gt;, which should you use? &lt;/p&gt;
&lt;p&gt;It depends entirely on what's available, and which engine you're going to use. If the font (or, font family) you want to use is only available in &lt;code&gt;.otf&lt;/code&gt; form, and you're going to use it in an excellent font engine like Adobe's own engine, then clearly: pick &lt;code&gt;.otf&lt;/code&gt;. If, on the other hand, you want a font that works best on the web, then it's really a toss-up between &lt;code&gt;.ttf&lt;/code&gt; and &lt;code&gt;.otf&lt;/code&gt; and the only real answer is "try them both, and see which one looks best". It might even be that at low point sizes the &lt;code&gt;.ttf&lt;/code&gt; looks best, but at higher point sizes, the &lt;code&gt;.otf&lt;/code&gt; looks better. If they're small fonts (i.e. the size of a JPEG image, which most fonts comfortably fall under) then why not just use both?&lt;/p&gt;
&lt;h2 id="more-to-come"&gt;More to come&lt;/h2&gt;
&lt;p&gt;In order to just get these posts out I'm going to keep some of them short, and this is one of the shorter ones, but rest assured that there's a lot to say about OpenType fonts, including how little most people know about them. And that's not an indictment, unless it's people espousing the virtue of one over the other without even realising they're both just OpenType fonts, only differing in the outline language, which is a large part of, but most certainly not the definitive aspect of, modern fonts.&lt;/p&gt;
&lt;p&gt;Next time I'll try to go into that statement a bit more: modern OpenType fonts are pretty dang complex pieces of software, and you could take the outline shapes for granted and still have a lot of amazingly detailed and rich data left to work with.&lt;/p&gt;
</description>
<category>Fonts</category>
<category>OpenType</category>
<category>TrueType</category>
<category>Type2</category>
<category>TTF</category>
<category>OTF</category>
<link>http://pomax.github.io/#gh-weblog-1449438115186</link>
<guid>http://pomax.github.io/#gh-weblog-1449438115186</guid>
<pubDate>Sun, 06 Dec 2015 21:41:55 GMT</pubDate>
</item>
<item>
<title> Github broke my blog, so I had to reset it...</title>
<description>&lt;p&gt;Github is usually pretty good when it comes to gh-pages and github.io hosting, but for some reason, an update to my pomax.github.io repository had broken whatever it is that github does when it deploys websites, to the point where even deleting my repository and then rebuilding it made things simply "not work".&lt;/p&gt;
&lt;p&gt;I ended up completely resetting the repository, which meant deleting it, which means all comments ever left by people are gone (I'm very sorry about that, thankfully the important thing about them was our conversation, not the historical record of that conversastion), and it turns out that github broke on the "gh-weblog" directory in the filessystem.  Renaming it to "gh-weblog-2" made things magically work (and boy do I wish I'd tried that first now, obviously), but creating a new dir "gh-weblog" and dropping files in there will land them into the repo, but keep them inaccesssisble on the github.io site. &lt;/p&gt;
&lt;p&gt;So if you were wondering where my articles had gone on Saturday, December 5th, now you know =(&lt;/p&gt;
</description>
<category>Github</category>
<category>Blog</category>
<category>Rebuilds</category>
<link>http://pomax.github.io/#gh-weblog-1449383023410</link>
<guid>http://pomax.github.io/#gh-weblog-1449383023410</guid>
<pubDate>Sun, 06 Dec 2015 06:23:43 GMT</pubDate>
</item>
<item>
<title> Bezier curves are not invariant under conformal mapping</title>
<description>&lt;p&gt;That's not a post title that'll sound very appealing to many people, but it's a question without an easy-to-google answer that I get asked more often than makes sense to keep answering on a case by case basis. So let me turn it into a URL on the internet instead.&lt;/p&gt;
&lt;p&gt;Invariance is defined as "any operation you can apply to the control points that define a Bezier curve, and then forming the curve, will yield the same curve as if you broke up the curve as a  sequence of individual points, and applied that operation to each of those, separately".&lt;/p&gt;
&lt;p&gt;Bezier curves are invariant under &lt;a href="https://en.wikipedia.org/wiki/Affine_transformation"&gt;affine linear transforms&lt;/a&gt;, which are those transforms that preserve parallel lines, but not necessarily distance between points or angles between lines. Basic affine linear transforms &lt;a href="https://en.wikipedia.org/wiki/Linear_map#Examples_of_linear_transformation_matrices"&gt;are&lt;/a&gt; rotation, reflection, translation, shearing, scaling, and projection.&lt;/p&gt;
&lt;p&gt;However, this is not the only class of transforms (obviously), and another transform that people tend to be interested in are &lt;a href="https://en.wikipedia.org/wiki/Conformal_map"&gt;conformal mappings&lt;/a&gt;, which preserve the (local) angle between lines, and this is a problem for Bezier curves.&lt;/p&gt;
&lt;p&gt;The simplest conformal mapping I can think of is the &lt;a href="https://en.wikipedia.org/wiki/Uniform_tilings_in_hyperbolic_plane"&gt;hyperbolic tiling&lt;/a&gt;, which maps the Euclidean ("rectangular") plane onto a circle plane instead, with a neat property:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the center of the Euclidean plane is the center of the circle.&lt;/li&gt;
&lt;li&gt;draw a line from the center, outward to infinity; this is a straight line in both the Euclidean plane and on the circle, but:&lt;/li&gt;
&lt;li&gt;a point along that line at distance D from the center of the Euclidean plane will lie at some distance D'&amp;lt;D from the "center" of the circle, and,&lt;/li&gt;
&lt;li&gt;any point along that line at twice the distance, E = 2D, on the Euclidean plane will lie on distance E' &amp;lt; 2D' - that is, outward travel at constant speed in the Euclidean plane, covering infinite distance, turns into monotone decreasing travel in terms of speed and distance, covering finite distance: you will never cross the "edge" of the circle, you just keep going slower and slower as you get closer and closer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are an infinite number of functions that achieve this kind of mapping, but all of them preserve local angles: If two straight lines crossed each other at 37 degrees on the Euclidean plane, then the lines themselves will no longer be straight, but at the exact point of their intersection, the angle between them will still be 37 degrees.&lt;/p&gt;
&lt;p&gt;Now, if you conformally map  the points that define a Bezier curve, and then draw a new curve with those mapped points, you are not guaranteed to get the same curve as if you'd treated the curve a sequence of points that together draw the curve, and then conformally mapped all of those instead. And we can prove this with a single example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A mapping that turns straight lines into circular arcs is a conformal mapping, preserving local angles of intersection.&lt;/li&gt;
&lt;li&gt;Bezier curves can perfectly represent straight lines.&lt;/li&gt;
&lt;li&gt;Bezier curves cannot perfectly represent circular arcs.&lt;/li&gt;
&lt;li&gt;This mapping will turn geometry that can be represented by Bezier curves into geometry that cannot be represented by Bezier curves&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Q.E.D."&gt;QED&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another way to think about this is that Bezier curves are formed using (iterated) linear interpolation, which relies on straight lines staying linear. If we deform them to some non-linear form, then we cannot use linear interpolation and still find the same resulting points.&lt;/p&gt;
&lt;p&gt;So there you have it. Are Bezier curves invariant under conformal mapping? No, they are not.&lt;/p&gt;
</description>
<category>Maths</category>
<category>Bezier Curves</category>
<link>http://pomax.github.io/#gh-weblog-1449335750620</link>
<guid>http://pomax.github.io/#gh-weblog-1449335750620</guid>
<pubDate>Sat, 05 Dec 2015 17:15:50 GMT</pubDate>
</item>
<item>
<title> "Tell me what some of your strengths are..."</title>
<description>&lt;p&gt;Last week I attended a work seminar on discovering your personal strengths and how to identify and curtail stress behaviour. Let me just give the summary first:&lt;/p&gt;
&lt;p&gt;Yes, it was incredibly useful, and I'd urge you to do something similar if you haven't yet.&lt;/p&gt;
&lt;h2 id="know-yourself"&gt;Know yourself&lt;/h2&gt;
&lt;p&gt;The main point is to learn what you're good at, so that you can focus your efforts into further developing skills that fall in categories related to where you are at your strongest.&lt;/p&gt;
&lt;p&gt;Yes, you might like doing a million different things, but if you really want to develop yourself, find out which few you're really going to be good at, and exploit that. Not necessarily give up on the others, just make sure you &lt;em&gt;focus&lt;/em&gt; on the ones that really come to you naturally.&lt;/p&gt;
&lt;p&gt;At the same time, know how you react when you get driven into a corner. Some of us are naturals at personal development, most of us are not, and the great thing about attending a seminar like this is that you get exposed to some of the psychology behind a few major generic personalities. For instance, here's my list of "strengths", spread over two categories:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Strategic thinking:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Input: "you crave to know more, and like to collect information and archive it". &lt;/li&gt;
&lt;li&gt;Learner: "you have a great desire to learn and continuously improve. In particular, learning, rather than the outcome, excites you".&lt;/li&gt;
&lt;li&gt;Intellection: "you are characterized by your intellectual activity. you're introspective, and appreciate intellectual discussions". &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Relationship building:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Relator: "you enjoy building close relationships, and find deep satisfaction in working hard with friends to achieve goals".&lt;/li&gt;
&lt;li&gt;Connectedness: "you think all things are connected and don't believe in coincidence. almost every event has a reason".&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And here's the thing: based on their simple definitions, not all of these strengths make a lot of sense. Thankfully, there are individualised descriptions of what each of these strengths mean, and so things start to make a lot more sense, and rather than "fortune cookie" information, one can actually learn something meaningful.&lt;/p&gt;
&lt;h2 id="meaningful-descriptors"&gt;Meaningful descriptors&lt;/h2&gt;
&lt;p&gt;The seminar I attended used the &lt;a href="http://strengths.gallup.com/110440/About-StrengthsFinder-20.aspx"&gt;Clifton Strengthsfinder 2.0&lt;/a&gt; test, based on data by &lt;a href="https://en.wikipedia.org/wiki/Gallup_%28company%29"&gt;Gallup&lt;/a&gt; gathered over quite a few years from over 100,000 participants. I like science, and if this data is going to say something "about me", then that's at least a decent sample size.&lt;/p&gt;
&lt;p&gt;No, of course the predictions won't be perfect, but it'll be good enough to act as starting point to acknowledge your own strengths and personality type, and exploit the strengths while working on minimizing the reactionary tendencies. So: who am I?&lt;/p&gt;
&lt;h3 id="strategic-thinking-input"&gt;Strategic thinking: Input&lt;/h3&gt;
&lt;p&gt;I like information. I like learning new things, and learning &lt;em&gt;about&lt;/em&gt; new things, but I don't particularly care about archiving, because I trust my brain to do that for me without having to bother with it. So what does "input" really mean? &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Chances are good that you can simplify the most complex, convoluted, or intricate procedure. People usually rely on you to offer clear and easy-to-comprehend explanations. Driven by your talents, you may notice that certain people turn to you for guidance. Maybe your willingness to share the knowledge you have gained over the years partially explains the fondness they have for you. Some individuals might have benefited from what you have read, observed, or experienced. Itâs very likely that you frequently use academic-sounding words to talk about your ideas or areas of expertise. You intentionally spend time broadening your vocabulary by looking up words in the dictionary and committing their meanings to memory. By nature, you occasionally combine your fascination for reading with your ability to figure out what sets specific individuals apart from everyone else. You might discover the things that interest someone. Then you may read more about these topics. Perhaps you aim to collect insights that inspire the person to take advantage of his or her one-of-akind talents, knowledge, and/or skills. Because of your strengths, you might gather ideas and information from reading publications that keep you up to date on particular types of current events. What you choose to peruse â that is, examine studiously â may reflect some of your personal or professional interests.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That makes a bit more sense than the generic summary. It also offers far more footholds when it comes to aspects of this strength that can be relied or built on.&lt;/p&gt;
&lt;h3 id="strategic-thinking-learner"&gt;Strategic thinking: Learner&lt;/h3&gt;
&lt;p&gt;I won't lie: I liked seeing this strength. I do very much enjoy learning new things, and seeing this as one of my strengths was basically one of those "yep, I knew it" moments. However, "I like to learn new things" is a pretty generic strength, so seeing the much bigger analysis was quite useful:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Instinctively, you endorse the importance of acquiring additional knowledge and gaining new skills. You regard education as an ongoing activity. Itâs very likely that you occasionally collect bits and pieces of information. At the time, the value of this material may not be apparent. In specific cases, you have found it useful to turn to some specialists for help. Perhaps these individuals can provide you with enough direction so you can ask some questions, render a few decisions, or try to map courses of action without upsetting anyone in the process. You avoid angering certain people by consulting with them before doing anything. Driven by your talents, you may long to gather certain types of information about specific individuals. Perhaps your âneed to knowâ is rarely satisfied. The more facts you gather, the easier it might be for you to understand someoneâs strengths, limitations, interests, likes, dislikes, or goals. You might be inclined to study human beings one by one. To some degree, your ongoing observations of selected individuals provide you with interesting insights into human nature. By nature, you intentionally include uncommon, highly technical, or sophisticated words in your vocabulary. You realize that language is a form of knowledge that gives you an upper hand â that is, controlling power â in conversations, debates, or discussions. It quickly establishes you as an authority figure in listenersâ minds. First, you capture their attention. Then you take charge of events, projects, meetings, or problem solving. Chances are good that you may be a solo performer. You might be determined to broaden your knowledge or acquire new skills. Perhaps you are drawn to the process of education.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And there you have it. Pretty much all of this rings true. And yes, on their own each of these phrases sound like a horoscope, but it's not the individual phrases that form the strength, it's the collection of all of them, applicable to this person.&lt;/p&gt;
&lt;p&gt;I'm okay with this.&lt;/p&gt;
&lt;h3 id="strategic-thinking-intellection"&gt;Strategic thinking: Intellection&lt;/h3&gt;
&lt;p&gt;This strength feels a little weird, because it's hard to go "why yes, I am intellectual" and not come off smug. The main problem is that "intellectual" and "smart" are often treated as the same thing, and in this particular case, they're not. I could give lots of examples, but instead it just makes far more sense to let the snippets do the talking:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Chances are good that you sometimes wish you could switch off your active brain. Even so, you may enjoy your time alone as you ponder ideas. Perhaps you want to test whether they make sense. Because of your strengths, you may be selective about the types of books or publications you read. They might contain information or tips that you can share with individuals you are training. Perhaps imparting knowledge, talking about your experiences, or passing along your skills gives you a certain degree of satisfaction. By nature, you may find it easier to befriend certain types of people if they tell you what they want to accomplish. Knowing that much, you might read some books, journals, newspapers, correspondence, or Internet sites to broaden your knowledge about their interests. When you can share information that helps people move closer to their goals, perhaps you can begin to understand each other a little better. Itâs very likely that you eagerly welcome opportunities to think out loud about ideas, theories, or philosophies. You derive pleasure from conversations that force you to ponder matters that exist only in the realm of thought, not in reality. Driven by your talents, you sometimes delight in having your very own tasks to perform. Perhaps you like to solo because it gives you quiet time to reflect on what you think or feel. Maybe you consider what you have done, are doing, or can do better.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="relationship-building-relator"&gt;Relationship building: Relator&lt;/h3&gt;
&lt;p&gt;This one confused me, because while I like deep relationships, I'm perfectly fine with shallow ones, too. The generic description didn't seem to match at all, but the detailed one certainly did:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;By nature, you are naturally open and honest about who you are, what you have done, what you can do, and what you cannot do. Your straightforward explanations and stories help listeners see you as you see yourself. You reveal your strengths and limitations. You are forthright and plainspoken. People generally seek your company and want to work with you. Many are impelled to move into action by your words and examples. Itâs very likely that you periodically are sought out by people whom you have befriended. They may trust you when you have taken time to know them individually. This may partially explain why certain people come back again and again for ideas or suggestions. They might realize you try to tailor your words of wisdom to fit their unique situations, needs, strengths, limitations, goals, or personalities. Driven by your talents, you may be convinced that you are measuring up to your potential. Perhaps you know when you are doing your best work or earning the highest grades you possibly can. Chances are good that you occasionally tell yourself that you are an effective mentor or trainer. Perhaps individuals benefit from the investment you make in them. Because of your strengths, you might do your best training after you become well-acquainted with someone. Perhaps you want to discover each individualâs unique talents, work style, goals, motivations, or interests. Maybe these insights tell you what suggestions to make or what tips to offer during coaching sessions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In fact, this very blog post is essentially proof of how true this assessment is: I'm right now telling you about something that a lot of people would consider pretty personal, and that last bit pretty much underlines how I even started this post: learning about different personalities and strengths, and how to work with those in oneself and other people, is fascinating, as well as functionally useful.&lt;/p&gt;
&lt;h3 id="relationship-building-connectedness"&gt;Relationship Building: Connectedness&lt;/h3&gt;
&lt;p&gt;And this one was a genuine surprise, at least based on the generic descriptions. It sounds very much like a "faith in the oneness of all things", which really doesn't describe my take on matters at all. I believe in a quantum universe (at least, for now. Physics is still developing), and while I don't believe in "coincidence", I also don't analyse things from just one perspective, and so the notion of "a coincidence" doesn't even make sense to me. There are so many different perspectives on single events that are all simultaneously in effect that even if you'd pretend there was a coincidence in one of those, that same coincidence would vanish in others. This strength felt like nonsense. But then this more personalised description actually made it make sense:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;By nature, you may get to know people individually in your quest to gain wisdom. Discovering the qualities that distinguish someone from everyone else might be an essential aspect of your search for truth. Driven by your talents, you might be fascinated with certain ideas, policies, or philosophies that affect human beings around the world. Because of your strengths, you may be able to accept unpredictable events in your life on the basis of sheer faith. Perhaps you sense there is a force greater than you at work in the world. Occasionally you can live with not knowing the exact reason why something good or bad happened to you and not to someone else. Chances are good that you sometimes think like a detective. You might search for and find obvious and not-so-obvious clues. You might determine which ones link together. Now and then, you notice gaps in your investigation. Some of these cannot be explained using reason alone. You may feel comfortable accepting what is unknown and unknowable. Why? To some extent, you trust that everything, everyone, and every action is somehow intertwined. Instinctively, you may be determined to make the acquaintance of certain individuals you identify as seekers of truth. Perhaps you are attracted to people who ponder philosophical questions such as âWhat is the meaning of life?â or âWhat is beauty?â or âWhat constitutes wisdom?â or âWhy do bad things happen to good people?â or âWhy should ordinary people like me even ask these kinds of questions?â&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Reading this, it basically reads as a description of being a university student who's taking a masters in A.I. which happens to be exactly who I was, and whose intellectual inheritance I still live today.&lt;/p&gt;
&lt;h2 id="weaknesses-the-reactionary-side-of-things"&gt;Weaknesses: the reactionary side of things&lt;/h2&gt;
&lt;p&gt;For the purposes of the seminar, when people get put on the spot, and stressed to a breaking point, the behaviour they might display is broadly categorised in three possible ways:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Complying: giving away the control over the situation and taking it from there.&lt;/li&gt;
&lt;li&gt;Protecting: walking away from the situation to protect oneself.&lt;/li&gt;
&lt;li&gt;Controlling: going into "getting shit done" mode and steamrolling anyone who doesn't do so as well.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Those are just words with short descriptors, and people often enough display more than one type of behaviour, depending on the situation. However, I know myself reasonably well in this respect, and I'm virtually always protecting:&lt;/p&gt;
&lt;p&gt;I will turn off any emotional attachment, and deal with problems in what is best described as "the vulcan way". I've certainly been abrasively critical in the past often enough for it to rub people the wrong way, and I've been trying to get better at &lt;em&gt;not&lt;/em&gt; being abrasive, but a seminar like this is a great supplement to introspection: it puts what you sort of already thought into a wider perspective, and most importantly gives you insight into how the way you behave under stress will affect others who are also operating under stress.&lt;/p&gt;
&lt;p&gt;If I'm stressed, and the person I'm dealing with is stressed as well (and for whatever reason. Not strictly work), then if they're of a complying nature, we're going to have problems. Because they'll want a resolution, and I'll be offering criticism without solutions. That won't get us anywhere, except "more stuck". Similarly, if they're controlling, they'll be coming up with what solution works, and I'll just shoot it right back down. And that's just the "practical" result, emotionally there's a lot of potential for resentment both ways, and things can get very nasty. &lt;/p&gt;
&lt;h2 id="-so-tell-us-some-of-your-strengths-"&gt;"So tell us some of your strengths..."&lt;/h2&gt;
&lt;p&gt;You know that question you get at job interviews, where they want to know what your strengths and weaknesses are? This is what they're talking about. This is why I'd recommend everyone to take a seminar like this even if you're between jobs, or even if you've yet to start on your first one. There's "knowing what you're good at", and there's "knowing the strengths that you can build on and exploit", and they're two different things. The first most people develop naturally, by virtue of just doing what they do. The second, everyone can use some help with.&lt;/p&gt;
&lt;p&gt;It also lets you know what you're not. That sounds a little weird, because there's an infinite world of infinite possibilities out there, but there're broadly speaking four categories of personalities and strengths that you want as part of an effective team, and a team made entirely of "learners" isn't going to be very useful. Fun, probably, but not something that makes business sense.&lt;/p&gt;
&lt;p&gt;I fall in the strategic thinking and relationship building categories. That means that if I'm put on a team, my contribution plays off of having other people with different skills: people with execution skills to keep us on track and meet deadlines, and people with influence skills to get the most out of all the team members as well as facilitate negotiations within the team. Also, having a good spread of different "reactionary" behaviours helps to make sure no one "agrees to be stuck in a rut". Obviously no one likes being stuck, but if we're all the same kind of reactionaries, things go real bad, real fast. Much faster than if there's a good spread.  &lt;/p&gt;
&lt;h2 id="the-take-home-message"&gt;The take-home message&lt;/h2&gt;
&lt;p&gt;For me, the take-home message from this seminar was that it's really useful to do a thing like this at least once, even if you don't have a job right now, or you think you know yourself: if you've never done a personal strengths test before then chances are good you think you know what you're good at, and you might know what makes your temper-self so problematic, but there is great value in seeing things affirmed, or even being shown that there are parts of you that you never thought about, but ring very close to home: knowing yourself is not just something that helps you, it also helps others work, or just be, with you.&lt;/p&gt;
&lt;p&gt;I've been paired up with a "buddy", and we'll be holding each other accountable for the action plan we've drawn up on how to work on our weaknesses while also trying to focus on what we think are our most exploitable strengths. That probably sounds pretty lame, but at the same time, it's two people being committed to helping each other better themselves in a "no judging" relationship.  &lt;/p&gt;
&lt;p&gt;That's a pretty sweet outcome for a seminar called "Leadership Discovery".&lt;/p&gt;
</description>
<category>Mozilla</category>
<category>Leadership</category>
<category>Strengths</category>
<category>Introspection</category>
<link>http://pomax.github.io/#gh-weblog-1442796369118</link>
<guid>http://pomax.github.io/#gh-weblog-1442796369118</guid>
<pubDate>Mon, 21 Sep 2015 00:46:09 GMT</pubDate>
</item>
<item>
<title> Mozilla released a tool I am excited about.</title>
<description>&lt;p&gt;&lt;strong&gt;tl,dr&lt;/strong&gt;: you should have a look at &lt;a href="https://thimble.mozilla.org"&gt;https://thimble.mozilla.org&lt;/a&gt;, and if you think "this is just a fancy jsbin", challenge yourself to first read &lt;a href="http://blog.humphd.org/thimble-and-bramble"&gt;http://blog.humphd.org/thimble-and-bramble&lt;/a&gt;, which explains in detail how this is nothing like the other "single tool sites" we had on the web until pretty much this month.&lt;/p&gt;
&lt;p&gt;With that said, Thimble has a larger story here for me, personally, and I'd like to tell you that story so that you might understand why I am genuinely excited about this tool.&lt;/p&gt;
&lt;h2 id="once-upon-a-time-i-was-a-java-developer-"&gt;Once upon a time, I was a Java developer.&lt;/h2&gt;
&lt;p&gt;In a round-about way, my first "being a programmer" identity started in University. As a kid I'd written things in &lt;a href="https://en.wikipedia.org/wiki/BASIC"&gt;Basic&lt;/a&gt;  and &lt;a href="https://en.wikipedia.org/wiki/Turbo_Pascal"&gt;Turbo Pascal&lt;/a&gt;, but it wasn't until University that I was taught how to write structured programs that were more than utilities or silly time wasters.&lt;/p&gt;
&lt;p&gt;My first "real programming" kicked in about three years into &lt;a href="http://gss.uva.nl/future-msc-students/information-sciences/content26/artificial-intelligence.html"&gt;my AI education&lt;/a&gt;, when we were taking a 10 credit course that involved working on real world AI applications, I worked on a java code base for running distributed sensors backed by software agents that collaborated on performing Bayesian reasoning about signal sources. It was interesting, and after the course was done, landed me my first student job continuing my work on it. I ended up designing the code architecture, which ended up landing me my first permanent job, and ultimately gave me a subject I could do a master's thesis on (yes, that's the order things happened in).&lt;/p&gt;
&lt;p&gt;Of course I was still programming my own things in my spare time, as well as maintaining some websites (most notably &lt;a href="http://nihongoresources.com"&gt;nihongoresources.com&lt;/a&gt;) and when a friend mentioned doing some log visualisations using a language called &lt;a href="http://processing.org"&gt;"Processing"&lt;/a&gt; (which is the worst name for a programming language that wants to be searchable on the internet btw), I figured I'd have a look at what this mystery language was. &lt;/p&gt;
&lt;p&gt;As it turned out, I really liked Processing: it was &lt;em&gt;like&lt;/em&gt; Java, but with more freedom: a simpler modeling concept, "global unless you enclose it" functions, immediate execution of code in an imperfect editor (the "PDE") that was good enough to write quick, super sweet visual things. What's more there was even a JavaScript port available, for running your pde files online. Not as Java Applets, but just "as content". &lt;/p&gt;
&lt;p&gt;I ended up using Processing enough that I started running into annoying inconsistencies, or even bugs, in the &lt;a href="http://processingjs.org"&gt;Processing.js&lt;/a&gt; port, and being familiar with &lt;a href="https://en.wikipedia.org/wiki/Internet_Relay_Chat"&gt;IRC&lt;/a&gt; I jumped into the #processing.js channel on irc.mozilla.org and started complaining whenever things didn't work. In some places, that gets you kicked out of a channel, but in this one, a user called "&lt;a href="http://blog.humphd.org"&gt;humph&lt;/a&gt;" flipped my complaints around and threw them back at me as suggestions on how bugs could be filed, discussed, and fixed, instead. Without knowing it, I was getting a lesson in how to be a member of a community, and it worked.&lt;/p&gt;
&lt;p&gt;My life in today's definition of open source really started there: I started filing bugs, I knew JavaScript well enough to write code for web pages, but the kind of JS needed to write Processing.js was different, so I started learning more about JS as I tried to figure out problems in Processing.js, and at some point decided I knew enough that I could patch problems when I ran into them, with a community of devs that were kind enough to help me through the process of getting those patches submitted and landed into the main codebase. I ended up, I think it's fair to say, a major contributor to Processing.js, I moved from the Netherlands to Canada and went from Java developer to freelance web dev with a love of JS, and that's where this story turns into my involvement with Mozilla.&lt;/p&gt;
&lt;h2 id="-i-want-to-put-a-team-together-"&gt;"I want to put a team together."&lt;/h2&gt;
&lt;p&gt;I can't talk about humph, or really, Dave Humphrey, without a certain amount of adoration (and that is a well-considered word).&lt;/p&gt;
&lt;p&gt;If you haven't heard of Dave, he's a Professor of Open Source with ties to Mozilla, teaching at &lt;a href="http://cdot.senecacollege.ca"&gt;CDOT&lt;/a&gt;, at &lt;a href="http://www.senecacollege.ca"&gt;Seneca College&lt;/a&gt; in Toronto, and if you use Firefox, there's a good chance you've enjoyed his work. Dave, to me, is in the category of people who look at something and go "what, 2 years from now, is a thing I want to be taking for granted as available and usable, that isn't there right now". And then, unlike many people, doesn't just blog about it, but sits down and figures out how to make it happen. The part that earns him my adoration is that one of his approaches is to inspire others to do the work, because he has the singular ability to explain his ideas in ways that hold up, and make you excited about the prospect of them becoming reality. &lt;/p&gt;
&lt;p&gt;And he was thinking of "a thing" that would require getting some people together to make it happen. Needless to say, he had my attention.&lt;/p&gt;
&lt;p&gt;Dave had been linking me to &lt;a href="http://marksurman.commons.ca/blog"&gt;blog posts&lt;/a&gt; about making the web about "making" instead of "consuming" by a guy called "Mark Surman" every now and then, and while I'd never heard of the man, his posts made a lot of sense. It wasn't until Dave explain his idea to me that things clicked: &lt;a href="https://en.wikipedia.org/wiki/Mark_Surman"&gt;Mark Surman&lt;/a&gt; was the director of the &lt;a href="https://en.wikipedia.org/wiki/Mozilla_Foundation"&gt;Mozilla Foundation&lt;/a&gt;, and the idea that Dave had was a project to foster "making on the web" through a Mozilla Foundation initiative that you might have heard of.&lt;/p&gt;
&lt;p&gt;"&lt;a href="https://webmaker.org"&gt;Webmaker&lt;/a&gt;"&lt;/p&gt;
&lt;h2 id="in-2012-i-joined-a-tiny-mozilla-foundation-"&gt;In 2012, I joined a tiny Mozilla Foundation.&lt;/h2&gt;
&lt;p&gt;I applied to the Mozilla Foundation as a software engineer when it was pretty small. Certainly not "5 people and a goat" levels of small, but when I joined, &lt;a href="http://creativecommons.org/staff/ryan"&gt;Ryan Merkley&lt;/a&gt; was still with the foundation with the explicit goal of growing it to self-sustaining size, and while I had initially expected to work on "Popcorn Maker", an online video mashup/remixing tool spearheaded by the fascinating &lt;a href="http://www.etherworks.ca"&gt;Brett Gaylor&lt;/a&gt; (from &lt;a href="http://donottrack.us"&gt;Do Not Track&lt;/a&gt; fame), I instead ended up working on a project that was about letting people write HTML in a friendly way, to allow them to learn HTML while also making things they wanted to make on the web.&lt;/p&gt;
&lt;p&gt;For quite a few months there was no name, and initially the "webmaker" name applied only to this particular tool, but as we folded more tools into the offering (popcorn maker and the "x-ray goggles", most notably), the overarching program became "Webmaker", and the tool that I was involved with became "Thimble". It was an interesting thing to work on: I learned a ton about patterns and antipatterns in the JavaScript world, and despite the tool being a single page editor, people responded positively. Thimble empowered people on the web in a way that they hadn't been until then, and that made it really important.&lt;/p&gt;
&lt;p&gt;But, as a developer, I wouldn't use it myself.&lt;/p&gt;
&lt;p&gt;In the same way that I won't do my job using &lt;a href="http://jsbin.com"&gt;jsbin&lt;/a&gt; or &lt;a href="http://jsfiddle.net"&gt;jsfiddle&lt;/a&gt; or &lt;a href="http://codepen.io"&gt;codepen&lt;/a&gt; as &lt;em&gt;tools&lt;/em&gt;, Thimble was too simple to address the needs of "everyone". It was great for sitting down to &lt;em&gt;with someone&lt;/em&gt;, and running them through a "zero to hero!" process where they walked away from the experience with the ability to create simple HTML pages for their own, personal content, and a way to put that content on the web (outside of social media postings), but there was no reason to ever use it if you already knew HTML and CSS and JS, and certainly not if you were a developer.&lt;/p&gt;
&lt;h2 id="thimble-got-upgraded-quite-a-bit-"&gt;Thimble got upgraded quite a bit...&lt;/h2&gt;
&lt;p&gt;After a year of Thimble, as well as several other tools being part of the Webmaker offering, we made a decision to give a new technology called &lt;a href="http://nodejs.org"&gt;Node.js&lt;/a&gt; a shot at the Foundation. As a JavaScript server side technology, it offered the benefits of "the same language everywhere", rather than the "JS in the browser, Python on the server" that we'd been using until then, and we quickly learned how to use Node.js and &lt;a href="http://expressjs.com"&gt;Express&lt;/a&gt; (in no small part thanks to colleague and friend jbuck, who did a phenomenal job at giving an hour and a half lecture on how to go from an empty file to a fully functional Express server, following best practices), and in the process rewrote parts of our tools to take advantage of the fact that everything could be done in JavaScript.&lt;/p&gt;
&lt;p&gt;We were able to add features and fix bugs much quicker than before, and we ended up releasing updates almost as fast as we could land bugs. But the Thimble tool stayed relatively samey: yes, there was progressively better support for error reporting in HTML and CSS, and we figured out how to safely allow script execution, so that people could write "real" web pages, but they were still just single pages.&lt;/p&gt;
&lt;p&gt;With the help of &lt;a href="http://thomaspark.co"&gt;Tom Park&lt;/a&gt; from &lt;a href="http://drexel.edu"&gt;Drexel University&lt;/a&gt; we came up with a way to present not just an editor but also a tutorial system, so that using Thimble for educational purposes would be easier, but ultimately it was still just single pages. &lt;/p&gt;
&lt;h2 id="this-was-not-a-tool-that-would-work-for-everyone-"&gt;This was not a tool that would work for everyone.&lt;/h2&gt;
&lt;p&gt;The problem with Thimble, and I'm making it sound like one but for the purpose of Thimble it mostly wasn't, was that it was aimed at an audience that I wasn't part of. In my professional life, I could do everything Thimble did, better, in tools I already had at my disposal on my computers. A desktop code editor and a browser gave me more power than the single flat file concept Thimble operated on, and so I would still use Thimble to teach people, but that was it.&lt;/p&gt;
&lt;p&gt;There were always ideas. "Wouldn't it be great if Thimble was like a real editor, but friendly when it needed to be, while being progressively less 'teaching tool' and more a real development tool as you level up your skills". It &lt;em&gt;would&lt;/em&gt; be great. But we couldn't make that tool. Having the tool work for educational setting was more important than spending time on making it better for a group of people who already had tools at their disposal.&lt;/p&gt;
&lt;p&gt;That makes sense, and that makes what makes the end of this story even more remarkable.&lt;/p&gt;
&lt;h2 id="atom-brackets-and-thimble-oh-my-"&gt;Atom, Brackets, and Thimble; Oh my!&lt;/h2&gt;
&lt;p&gt;Sever-side JavaScript did more than just skyrocket Node.js's popularity: it also allowed for some "chromeless" browser experiments ("chrome" not just being the name of Google's browser, but in the browser world also being the name for every part of the the browser's interface that isn't "the part that shows you the webpages". The term was in already widely used when Google appropriated it) which ended up spawning "pure JS" code editors. Code editors called &lt;a href="https://atom.io"&gt;Atom&lt;/a&gt; and &lt;a href="http://brackets.io"&gt;Brackets&lt;/a&gt; hit the scene, being experiments on using a chromeless browser as a UI framework, and using pure JS as the editor engine. Presented as normal desktop applications, but "powered by the web", there was a lot of love for these new flavours of code editors.&lt;/p&gt;
&lt;p&gt;But: if they ran in a headless browser, there wasn't any real reason why they shouldn't be able to, at least in principal, run in real browsers, online.&lt;/p&gt;
&lt;p&gt;And that's where Dave showed his genius: he took Adobe's "Brackets" editor, and at &lt;a href="http://2013.mozillafestival.org"&gt;MozFest 2013&lt;/a&gt; showed off that it might be possible to put it in the browser, and use it as the code editing part of Thimble, rather than relying on &lt;a href="https://codemirror.net"&gt;codemirror&lt;/a&gt;, so that people would have all the power of a true code editor at their disposal. There was a confluence of technologies that he knew of that could take "making things on the web" to a whole new level, and listening to him describe it, it was the kind of thing I wanted to use.&lt;/p&gt;
&lt;p&gt;Imagine opening a code editor with file management, running a localhost server for proper &lt;code&gt;http://&lt;/code&gt; protocol testing, and a browser with live reloading so you could see the results instantly. As a dev, that sounds a lot like how I do my work already.&lt;/p&gt;
&lt;p&gt;Now imagine not doing those things separately because the browser just does &lt;em&gt;all those things&lt;/em&gt;. A true file system, a true code editor, a true zero-conf HTTP server, true live reloading, all of it, just working. No questions asked. Start it up, and it all just... works.&lt;/p&gt;
&lt;p&gt;To me, that's the future. And that's what Dave was suggesting was possible. If we could put in the time to make it work.&lt;/p&gt;
&lt;h2 id="sometimes-tough-choices-aren-t-fun"&gt;Sometimes, tough choices aren't fun&lt;/h2&gt;
&lt;p&gt;Unfortunately, we didn't have the man hours to make that happen. I really, really loved the idea, but we didn't have the time or the people to stop working on Webmaker, and the Thimble we already had, and instead work on this new thing. This made me sad: it felt like we were focusing on the wrong things by sticking with the Thimble we had. Imagine growing up in a country rife with corruption, and discovering "Norway" is a real thing: while Thimble was still the same tool it had been before, I had seen a glimpse of what it &lt;em&gt;could&lt;/em&gt; be, and how much better that was, and simply knowing that the technology allowed for this amazing thing, devalued the Thimble we worked on for me, instead.&lt;/p&gt;
&lt;p&gt;Fortunately, the Mozilla Foundation is about fostering a "maker attitude" on the web, and promoting digital literacy, not "maintaining a set of tools in perpetuity" and even though Thimble was a tool that helped people express themselves creatively on the web, while learning about how the web works, we were constantly looking at what else we could do, or what we could do instead, to instill those core ideas in people, but not necessarily with the same tools all the time. We came up with Appmaker, which allowed people to make web apps, using web technologies - it was fun, it ended up not working as well as we'd hoped, and so we tried something else. We took the lessons we learned and made a page builder that used templates to allow people to make simple pages that also worked as apps on platforms that supported WebApps (like Android and Firefox OS).&lt;/p&gt;
&lt;p&gt;We looked at the world, and saw a significant part of the world experiencing massive friction between "what the web can do", and "how it was experienced": over a billion people are slowly coming online all over the world right now (even in places like Europe or the US), and the only "internet" they get is through preinstalled apps on their phone; they use Facebook, Twitter, Instagram, but not a browser, that supposedly ubiquitous gateway to the world wide web. The browser is supposed to open up the whole wide world to you, whereas branded apps like Facebook's client are like the CompuServe and AOL of days gone by; you get content presented in one way. Their way.&lt;/p&gt;
&lt;p&gt;This is not a good thing, and so we changed what the app we made could do, transforming it into an &lt;a href="https://beta.webmaker.org"&gt;Android app&lt;/a&gt; (available in the &lt;a href="https://play.google.com/store/apps/details?id=org.mozilla.webmaker"&gt;Play Store&lt;/a&gt; for free) that lets you build simple multi-view websites with text, images, and navigation buttons, to cater to the needs of the people we talked to in the various countries in the world where internet connectivity is starting to boom. It's not done, but the response from people for whom the app makes sense because they've been getting, effectively, locked-in devices has been great.&lt;/p&gt;
&lt;p&gt;At the same time, we deprecated the tools we had been using for the last few years, &lt;a href="https://blog.webmaker.org/whats-next-for-webmaker-tools"&gt;moving some to new homes and retiring others&lt;/a&gt;. And that's where this story comes full circle:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;We killed off Thimble. And replaced it with Thimble.&lt;/strong&gt; &lt;/p&gt;
&lt;h2 id="letting-others-do-the-work-you-can-t"&gt;Letting others do the work you can't&lt;/h2&gt;
&lt;p&gt;I'm going to borrow a page out of Dave's book, and profess my enthusiasm for the "let others do the work when you can't do it" doctrine, even though it's a bit of a boomerang: while we were doing all this at the Mozilla Foundation, various people were working on the various technologies that could be glued together as the kind of vision-of-the-future Thimble that Dave had talked about in 2013.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/modeswitch"&gt;Alan Kligman&lt;/a&gt; developed a &lt;a href="https://github.com/filerjs/filer"&gt;POSIX filesystem&lt;/a&gt; that ran on top of &lt;a href="https://en.wikipedia.org/wiki/Indexed_Database_API"&gt;IndexDB&lt;/a&gt;, Dave had been working on getting Brackets itself to &lt;a href="https://github.com/humphd/brackets/tree/bramble"&gt;work in the browser&lt;/a&gt;, the web itself had landed, or had in draft, several new technologies that made data management and communication between processes, documents, and service workers easier, and eventually everything was available for Dave to put together a team of students and see if they could combine everything into the kind of Thimble I had been hoping for since Dave showed me Brackets.&lt;/p&gt;
&lt;p&gt;On Monday, August 31&lt;sup&gt;st&lt;/sup&gt; 2015, that thing officially &lt;a href="http://thimble.mozilla.org"&gt;became real&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="the-new-thimble-is-a-dream-tool-and-i-love-it"&gt;The new Thimble is a dream tool, and I love it&lt;/h2&gt;
&lt;p&gt;Here's a true thing: the day the new Thimble got announced, I stopped using jsbin, jsfiddle, codepen, and all those other "make a quick html/css/js thing online" tools. Overnight, they had become obsolete. Anything I used them for could be done better in the new Thimble, and where jsbin or codepen let me be creative in a "single thing", the new Thimble lets me be creative without a ceiling. It's simplified the tools necessary to have a live server running with a full file system at my fingertips to "just open thimble.mozilla.org", and I can make things as simple or as complicated as I want.&lt;/p&gt;
&lt;p&gt;It's a true code editor that I can use to make as many files, in as many directories, as I need to properly organize and work on my code. There is undo/redo, but I don't ever have to hit save: my changes are synced by the extremely clever file system that Thimble runs on top of. It has an invisible zero-conf webserver running &lt;em&gt;in the browser&lt;/em&gt; that shows me the result of what I'm writing right next to the content I'm working on. I no longer need a live-server or a &lt;code&gt;python -m SimpleHTTPServer&lt;/code&gt; anymore, it's all &lt;em&gt;just there&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;And here's a thing I didn't even think I would say as a developer: thanks to the new Thimble just... working, I don't even &lt;em&gt;need git&lt;/em&gt; anymore.&lt;/p&gt;
&lt;p&gt;No, I don't get revision control (though really, "I don't get revision control &lt;strong&gt;yet&lt;/strong&gt;", because remember that the current &lt;a href="https://thimble.mozilla.org"&gt;https://thimble.mozilla.org&lt;/a&gt; is really just a Minimum Viable Product launch: we've only just begun to see what it can do, and now is that time to start dreaming about fancy features), but I can write my code, publish it to the web for free, and have people be able to see the code I used because they can click a button to fire up thimble with my project loaded up as a forked copy for themselves.&lt;/p&gt;
&lt;p&gt;If I just want to write some Proof of Concept code, or demonstrator code for an article I'm writing, or example code for something I'm explaining to someone online that might be useful later on, I don't need to set up a git repo, with a &lt;code&gt;gh-pages&lt;/code&gt; branch. I can just work in Thimble, hit "publish" (which will update what is online if I'm republishing the same project, with changes) and move my attention elsewhere in the knowledge that my stuff's been updated online for everyone to play with, and my code's safe and sound on a Mozilla server somewhere. And any time I want to dive "deeper", I can just tell Thimble to export my entire filesystem as a .zip file, and then do whatever I feel I need to do.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The new Thimble is taking away the need for tools I thought were essential in my life.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I honestly think that's the most impactful statement I can make here. Thimble is solving problems I didn't know I had, and that makes me super happy, and excited about the future.&lt;/p&gt;
&lt;h2 id="so-in-conclusion-"&gt;So, in conclusion:&lt;/h2&gt;
&lt;p&gt;Go try out the new &lt;a href="https://thimble.mozilla.org"&gt;https://thimble.mozilla.org&lt;/a&gt;, and &lt;a href="https://github.com/mozilla/thimble.webmaker.org/issues"&gt;let the team know what you think of it&lt;/a&gt;, and what you can imagine as, in the future, being obvious things you already use it for, that it can't do today.&lt;/p&gt;
&lt;p&gt;Thanks for reading, and I need to be off to write code for my next blog post on writing fonts as source code. I already have Thimble open in another tab with demonstrator code doing amazing things.&lt;/p&gt;
</description>
<category>Mozilla</category>
<category>Thimble</category>
<category>HTML</category>
<category>CSS</category>
<category>JS</category>
<link>http://pomax.github.io/#gh-weblog-1442700129236</link>
<guid>http://pomax.github.io/#gh-weblog-1442700129236</guid>
<pubDate>Sat, 19 Sep 2015 22:02:09 GMT</pubDate>
</item></channel>
</rss>
