<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<atom:link href="http://pomax.github.io/gh-weblog-2/rss.xml" rel="self" type="application/rss+xml" />
<title>Pomax.github.io</title>
<description>My blog on github</description>
<link>http://pomax.github.io</link>
<lastBuildDate>Wed, 24 Feb 2016 17:39:00 GMT</lastBuildDate>
<pubDate>Wed, 24 Feb 2016 17:39:00 GMT</pubDate>
<ttl>1440</ttl>
<item>
<title>Github changes to icon SVG from fonts, for no clear reason</title>
<description>&lt;p&gt;In a &lt;a href="https://github.com/blog/2112-delivering-octicons-with-svg"&gt;recent post on their blog&lt;/a&gt;, &lt;a href="github.com"&gt;github&lt;/a&gt; announced that  they've moved away from icon fonts in favour of SVG. In itself perfectly fine, use whatever works best, and if fonts aren't working for you, switch; but their explanation of what was wrong makes several kinds of no sense.&lt;/p&gt;
&lt;p&gt;This is going to be a bit of a rant, it's going to conclude with "should they switch? absolutely! yay github" but the rest of the text is about how their blog post doesn't feel like it actually contains any proper rationale for the move. You can stop reading if you only wanted to know my concluding thoughts. As far as I'm concerned, they did the right thing, for the wrong reasons.&lt;/p&gt;
&lt;p&gt;The images shown on the blog post to show a "badly blurred font icon" vs "a nicely crisp image icon" are both blurry. Neither is particularly better than the other at the scale shown, so there is no case there to determine which is better. They're both bad.&lt;/p&gt;
&lt;h2 id="icon-font-rendering-issues"&gt;Icon font rendering issues&lt;/h2&gt;
&lt;p&gt;The first section is 100% true. Github notes that "Icon fonts have always been a hack", and they have. Unicode these days comes with dingbats/windings, symbol sets, and emoji, but none of those things are true icons. Icon fonts will typically either inappropriately use "real letter" code points for icons ("you use class &lt;code&gt;.left-arrow&lt;/code&gt; but it renders because it asks the letter &lt;code&gt;a&lt;/code&gt; from the font, which happens to be an icon) or they use PUA (the Private Use Area of fonts) and some kind of substitution ruleset for finding icons in that area (because you can't really type PUA letters on your keyboard).&lt;/p&gt;
&lt;p&gt;So far so good. Except that's not a reason to switch, that's merely stating the facts. Fonts for icons are hacks. Do they get the job done? Certainly. This does not count towards the "reasons to switch" yet.&lt;/p&gt;
&lt;h2 id="page-rendering-improvements"&gt;Page rendering improvements&lt;/h2&gt;
&lt;p&gt;There was an assumption that SVG would improve page performance. However, as they note later, &lt;a href="https://cloud.githubusercontent.com/assets/54012/13176951/eedb1330-d6e3-11e5-8dfb-99932ff7ee25.png"&gt;there's no clear evidence of that&lt;/a&gt;. To be clear: this is completely the right thing to do: you have two possible options, you test both, and then use metrics to determine which one is better. But if there is no real difference then it cannot count as reason to switch. It is in fact a reason to tell others "if this is why you're thinking of switching, it doesn't matter, here's our findings: ..."&lt;/p&gt;
&lt;p&gt;So we have no reasons to switch yet.&lt;/p&gt;
&lt;h2 id="accessibility"&gt;Accessibility&lt;/h2&gt;
&lt;p&gt;This one's interesting. "some people use their own fonts, so our fonts don't render" may be a problem. Github has &lt;em&gt;a lot&lt;/em&gt; of users, but "people using their own fonts" typically also means those people do so by choice. If overriding the icon font is adverse, they presumably have the power to each fix that, but chose not to. That's not Github's responsibility to fix, but it can certainly be something Github can fix "as one party" instead of every user who's affected fixing it "as a million parties". It's not an argument to switch from fonts to SVG in general, but it's an argument for why Github, as a trusted and liked millions-of-users-daily service, to lend a helping hand.&lt;/p&gt;
&lt;p&gt;The second argument concerns screen readers, but glosses over the nature of an icon in a UI. Icons are non-semantic, they're decoration around the actual thing. The hypothetical ability to add readable &lt;code&gt;alt&lt;/code&gt; texts because the icons are now true images does not apply: if your icon needs an alt-text read out to the user in order for them to understand your UI, that icon is not an icon, it's a genuine semantic element and you should not be using an icon to hide what it is. In fact, you confuse &lt;em&gt;everyone&lt;/em&gt; with that kind of icon use, not just people who need, or are better served by using, screen readers.&lt;/p&gt;
&lt;h2 id="properly-sized-glyphs"&gt;Properly sized glyphs&lt;/h2&gt;
&lt;p&gt;This one's a bit odd, because it both makes sense and absolutely not. I'm paraphrasing, but this section has a rational along the lines of "vector fonts render horribly at small point sizes", which is [absolutely true](&lt;a href="http://rastertragedy.com"&gt;http://rastertragedy.com&lt;/a&gt;, "as opposed to SVG, which renders pixel-perfect", which is absolutely false.  Both are vector graphics, and both suffer from the exact same problem scaled down. However, fonts can come with instructions on how to correct outlines, and SVG cannot. Unfortunately the choice between &lt;code&gt;ttf&lt;/code&gt; and &lt;code&gt;otf&lt;/code&gt; matters &lt;em&gt;a lot&lt;/em&gt; here: &lt;code&gt;ttf&lt;/code&gt; uses true instructions, and &lt;code&gt;otf&lt;/code&gt; uses hints. If you try to use an &lt;code&gt;otf&lt;/code&gt; icon font with a render engine that doesn't have a good "what should I do with these hints" implementation, your icons will look terrible. Turns out that's the state of technology right now. So that's an argument to use &lt;code&gt;ttf&lt;/code&gt; rather than `otf, rather than exchanging one vector format for another.&lt;/p&gt;
&lt;p&gt;Vector graphics are always worse than bitmaps if you want pixel-perfect icons, so: why not use bitmaps for the "it scales poorly" cases? I know what you're thinking: "but modern fonts are vector fonts!" Not really, no. Modern fonts can do &lt;em&gt;a lot&lt;/em&gt; of things, and one of those things is that they can contain pixel-perfect bitmaps to be used when a sequence of glyphs needs to be shaped at &lt;em&gt;specific&lt;/em&gt; point sizes, for pixel-perfect rendering (using the EBDT, Embedded Bitmap Data Table). If your icon font of choice doesn't come with those, then that's an argument for improving things on the font side, so that everyone who uses that font gets a better deal out of it.&lt;/p&gt;
&lt;p&gt;Of course, in the mean time you might consider changing over to SVG because you want to solve the problem "now", and I like Github and assume they looked and couldn't find one. But as phrased, this section didn't actually gave a good rationale for switching to SVG so much as highlighted a misunderstanding on how modern fonts work and showing that assumptions were made about what the problem was. To someone familiar with the inner workings of fonts, this section reads as a symptom description, not a problem description, and fixing the symptom does not solve the underlying problem. &lt;em&gt;Any vector graphic&lt;/em&gt; will render terribly at low point sizes, trading one for another just &lt;a href="https://en.wikipedia.org/wiki/Buck_passing"&gt;passes the buck&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="ease-of-authoring"&gt;Ease of authoring&lt;/h2&gt;
&lt;p&gt;No two ways about it: if you want to control your icons, SVG is a hell of a lot easier than fonts. Go with SVG! It's the right choice! &lt;/p&gt;
&lt;h2 id="we-can-animate-them"&gt;We can animate them&lt;/h2&gt;
&lt;p&gt;Get out. If you're arguing accessibility as part of your rationale, don't even go here.&lt;/p&gt;
&lt;h1 id="should-github-switch-"&gt;Should Github switch?&lt;/h1&gt;
&lt;p&gt;Of course they should, it's their site. If they feel better with an SVG solution compared to fonts, then that's all the rationale they need. But then it would be nice if their blog post acknowledged that the only objective justification that was described, performance, turned out to not be significantly impacted by the switch, and that they've gone through with the switch mostly because it's easier to work with from a continuous update perspective, and also quite likely because if you've done all that work already to test deploying SVG instead of fonts, why not flip the switch.&lt;/p&gt;
&lt;p&gt;I'm sure we'd understand that, too.&lt;/p&gt;
</description>
<category>Github</category>
<category>Fonts</category>
<category>SVG</category>
<category>Icons</category>
<link>http://pomax.github.io/#gh-weblog-1456332505750</link>
<guid>http://pomax.github.io/#gh-weblog-1456332505750</guid>
<pubDate>Wed, 24 Feb 2016 16:48:25 GMT</pubDate>
</item>
<item>
<title>You probably need Chocolate Bread Pudding in your life.</title>
<description>&lt;p&gt;I made an &lt;a href="http://imgur.com/gallery/ObTlB"&gt;imgur image album&lt;/a&gt; as an illustrated guide to making chocolate bread pudding - or at least, the kind I make these days (less death-by-chocolate, more tasty-not-too-sweet brownie alternative). If there's requests I'll turn that into a post on this blog, but the imgur link should be pretty stable so for now I'll leave it at that.&lt;/p&gt;
&lt;p&gt;&lt;img src="http://i.imgur.com/GDjqsU0.jpg" alt=""&gt;&lt;/p&gt;
</description>
<category>Cooking</category>
<category>Baking</category>
<category>Chocolate</category>
<link>http://pomax.github.io/#gh-weblog-1455215020166</link>
<guid>http://pomax.github.io/#gh-weblog-1455215020166</guid>
<pubDate>Thu, 11 Feb 2016 18:23:40 GMT</pubDate>
</item>
<item>
<title> A blog post about kitchen knives</title>
<description>&lt;p&gt;I've been promising to write this blog post for a while after joking about how the fair number of knives I use in the kitchen would probably fill an entire blog post, but for reasons that have been lost to time never got to it. That changes now.&lt;/p&gt;
&lt;p&gt;I like working in the kitchen, I started as a kid, kept it up as a student, and had the pleasure to have access to a good kitchen with gas range after moving to Canada from the Netherlands. When it came time to buy our own house, we specifically bought one with a large kitchen and gas range, and I still get my cook on on a daily -if not more- basis.&lt;/p&gt;
&lt;p&gt;Now, cookery requires ingredients, and ingredients quite often require cutting, so you buy a cheap knife set, you use two or three of them frequently, and you can get by quite well. The price of a knife set does not determine how well the knives will work, and some of the more expensive ones (I'm looking at you, Global) are absolutely terrible to have to work with on a daily basis. Better to get a cheap set that cuts well and have a friend grind down the handle a bit where the metal bits and wooden bits don't quite line up, than to pay ten times as much or more for great quality that's horrible to work with.&lt;/p&gt;
&lt;p&gt;Now, two or three knives is literally all you need. If I were caught in a situation where I had to prepare food for 40 people and all I had was a chef knife and a paring knife, I'd be fine. But they do make specialty knives, and having them makes certain tasks either more fun, or much easier, so I've picked up a few knives over the years and of those, this blog post will highlight the ones I use regularly, meaning either daily, or at least several times a month. Except for two, but we'll get to them.&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-01.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Let's talk about this collection, shall we?&lt;/p&gt;
&lt;h2 id="the-chef-knife"&gt;The chef knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-02.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;The chef knife is, as far as I'm concerned, the absolute minimum necessary to "do everything". It can slice, it can dice (well, with your help), it can chop, it can pare (while a little inconveniently, it absolutely can), it can fillet, it can crush, as far as I'm concerned it is the only knife you &lt;strong&gt;need&lt;/strong&gt; in a kitchen. Although that doesn't mean you should use it for all those things because you'll probably have at least one or two knives that can do one or more of those things better. &lt;/p&gt;
&lt;p&gt;I have a few chef knives, but these are the two I use on a daily basis. The top is essentially my backup for when more than one person's in the kitchen, if it's just me I'll typically use... well, perhaps the level of wear will give it away: I use the knife with the broken tip. It's from a $30 knife set I bought over 10 years ago, and is as sharp as any $200 knife. In terms of actual weight, it's fairly heavy, but it's extremely well balanced so it feels like it has very little true weight to it, and it dances around in your hand if you want it to. Yes, that's the level of satisfaction a nice kitchen knife can give &lt;/p&gt;
&lt;p&gt;I use these for big cuts, slicing, as well as chopping up things. Bog standard use really.&lt;/p&gt;
&lt;h2 id="the-utility-knife"&gt;The utility knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-03.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;The utility knife is for smaller jobs. The blade's too short for most things a chef knife is good for, but it's great for incisions and stripping (both of those apply to vegetables as much as to meats).&lt;/p&gt;
&lt;h2 id="the-paring-knife"&gt;The paring knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-04.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;A paring knife is the scalpel of the basic set. It's not good for any kind of slicing, but it's great for precision cuts, and cutting things away from each other with minimum spill-over, or creating small cutouts (like taking a stem out of a bell pepper. No need to waste tasty vegetable goodness by cutting off the entire top). &lt;/p&gt;
&lt;h2 id="a-nice-sharp-cleaver"&gt;A nice sharp cleaver&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-05.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;While this looks like a super heavy thing, and it's certainly heavier than a regular knife, this old Solingen cleaver is essentially the same as a thick Chinese cleaver. It has a sharp edge, and can be used for cutting, chopping, and because of the geometry of the blade near the handle, shucking oysters or other shellfish. And, of course, it's a cleaver so you can use it to cleave, although it's mostly for cleaving &lt;em&gt;soft&lt;/em&gt; things.&lt;/p&gt;
&lt;p&gt;Simple rule: things with sharp edges are meant for cutting, not hitting. The value in a cleaver is its size and solidity; do the initial cut, drive the cleaver in, then drive it through. The softer the thing you're cleaving, the more you can "chop" rather than drive, but this is not TV, and you don't wield a regular cleaver like it's a hatchet.   &lt;/p&gt;
&lt;p&gt;For instance: chunking up Chinese barbecue pork: yes. cleaving through a lamb shoulder: no. Splitting a squash: absolutely. Chopping a chicken thigh in half: ... kind of not, no. I mean, you can if you absolutely have to, but really you want the next item on this list instead.&lt;/p&gt;
&lt;h2 id="a-nice-not-really-sharp-bone-cleaver"&gt;A nice not-really-sharp bone cleaver&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-06.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;This is a real cleaver in the sense of "what people think of when you say cleaver". It basically a kitchen axe with a relatively dull edge. You don't cut things with this (you plain old can't) but you use it as a splitter to get through bones. Or, sometimes, things that have frozen up pretty solid. &lt;/p&gt;
&lt;p&gt;Unlike a sharp cleaver, bone cleavers &lt;em&gt;are&lt;/em&gt; wielded like hatchets: it's pretty much what they are. I obviously don't use this every day, it's a specialty knife (if we can really still call it a knife) but this is the only tool I want to use when I do need to use it.&lt;/p&gt;
&lt;h2 id="a-yanagi-sashimi-knife"&gt;A yanagi (sashimi) knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-07.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;"Japanese knives!", aye. The yanagi knife is a sashimi knife, meaning it's intended for single cut, precision-slicing. It might look a bit long, but honestly I'm looking into replacing it with a longer version: sashimi is raw, which means nothing will have been done to the cut to hide imprecisions or imperfections, and the human tongue is an amazing organ: it will detect rough cuts. The longer the knife, the longer you can make a single, constant pressure cut, which means the cut surface will be absolutely smooth. Unlike a chef knife, where you're often cutting away from yourself, you cut towards yourself with a sashimi knife. Ever seen or bowed a violin? It's pretty much like that. Very little pressure, let the knife do the cutting as you pull it in.&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-08.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Unlike the previous knives, this is a single sided knife: it's perfectly flat on the left side, and ground to an extremely sharp edge on the other. At least for sashimi, this means you don't disturb half the cut by "pushing it out of the way", which a "normal" double sided knife will do.&lt;/p&gt;
&lt;h2 id="a-deba-fish-knife"&gt;A deba fish knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-09.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Fish knife! This is a thick, heavy knife with a single sided edge. It's extremely sharp, and great for deboning fish. If you have an whole salmon (and I live in Vancouver, a whole salmon can be yours for about $10) then this knife is all you need to turn it into two beautiful full length fillets.&lt;/p&gt;
&lt;h2 id="an-usuba-vegetable-knife"&gt;An usuba vegetable knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-10.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Finally, the Japanese vegetable knife. Again, single sided edge, and it's incredibly sharp. It sits at the intersection of chef knife and cleaver, and is great for splitting not-too-hard vegetables, as well as chopping up vegetables if presentation is going to matter, like uniformly hair-fine julienne, peeling a cucumber to get the entire skin as a single sheet, getting wafer thin slices of vegetable, et cetera.&lt;/p&gt;
&lt;p&gt;I love this knife to bits. &lt;/p&gt;
&lt;h2 id="the-ol-bread-knife"&gt;The ol' bread knife&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-15.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;On to pure utility: the bread knife. Some people don't have one, some do but never use it, in our household this thing is pretty much used on a daily basis. It's not actually all that good at slicing bread, but it's a great knife for cutting frozen items, as well as "opening up" a bread for slicing, which basically means cutting it in half so that the next knife on the list can be used...&lt;/p&gt;
&lt;h2 id="a-bread-saw"&gt;A bread saw&lt;/h2&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-11.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;That's right, it's a saw. On a handle. For slicing bread. After you open up a bread with the regular breadknife, all the other slices are simply "put this on bread so that the wood touches the side and the saw touches the top. Saw off slice". It is perfect.&lt;/p&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-12.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;It's also literally just a saw blade. I stopped counting the number of times I accidentally cut myself on this thing. Most knives don't draw blood just by being tapped. This thing? No mercy.&lt;/p&gt;
&lt;h2 id="keeping-knives-sharp"&gt;Keeping knives sharp&lt;/h2&gt;
&lt;p&gt;And let's not forget the things we need to make sure knives stay usable. Knife edges wear off over time and with use, and hard as metal is, a very sharp blade is thin, and can easily dent or chip. To deal with this, there's three tools in my kitchen for making sure the knives stay usable. &lt;/p&gt;
&lt;h3 id="a-good-steel"&gt;a good steel&lt;/h3&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-14.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;First off, a good steel. Steels are not for sharpening a knife, they're for making sure any dents in the cutting edge are smoothed out by "steeling" it: rubbing the edge along the steel, doing both sides to make sure dents in either direction and smoothed back in line with the rest of the edge. Do this when you're done with your knife after cutting something that offered a bit of resistance and your knife'll last a bit longer. &lt;/p&gt;
&lt;h3 id="grind-stone-s-and-carbide-shaver"&gt;grind stone(s) and carbide shaver&lt;/h3&gt;
&lt;p&gt;&lt;img src="/gh-weblog-2/images/knives/knives-13.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Of course, steeling isn't sharpening, and your knife &lt;em&gt;will&lt;/em&gt; lose its edge eventually. When that happens, it's time to whip out the grinding stones. I have a combination 400 grit/2000 grit whetstone, and badly dulled knives first get a treatment at 400 before moving on to 2000.&lt;/p&gt;
&lt;p&gt;Finally there's that little "speedy sharp" thing: that's a carbide steel strip on a handle. A word of warning: this is &lt;em&gt;not&lt;/em&gt; a sharpener. This is a shaver, and does what that word implies: the carbide steel strip is much, much stronger than the metal used to make  your knife, and running this across the cutting edge literally shaves off some of the metal. It's a very fast way to give a knife a quick edge, but you've just reduced your knife width by far more than you would if you used a sharpening stone. Use this as your only method of sharpening and you're literally going to just run out of knife. That said, I use this to quickly strip a knife of whatever oxidation or environmental coating it may have picked up when I bake baguettes, where getting a good scoring across the loaves before the bread goes into the oven is far more important to me than wearing out a knife. Just stroke the edge with minimal force a few times and you're good to go. As long as you remember to also give the knife a quick rinse because again: you're shaving it. There will be residue.   &lt;/p&gt;
&lt;h1 id="and-that-s-it-"&gt;And that's it.&lt;/h1&gt;
&lt;p&gt;That's all the knives I use regularly enough to feel they warrant mention - Notably missing are my Chinese cleaves (#1, #2, and #5) that I basically stopped using because between the chef knives and Japanese knives, there's nothing they're actually better at, and while nifty, things like grapefruit knives are so special purpose that if you need them, you know why, and if you don't know why, you won't need them.&lt;/p&gt;
</description>
<category>Kitchen</category>
<category>Knives</category>
<category>Knife</category>
<link>http://pomax.github.io/#gh-weblog-1454267122337</link>
<guid>http://pomax.github.io/#gh-weblog-1454267122337</guid>
<pubDate>Sun, 31 Jan 2016 19:05:22 GMT</pubDate>
</item>
<item>
<title> "git init" your way to peace of mind.</title>
<description>&lt;p&gt;This is going to be a short post, but it's one that can make the difference between you being happy, and crying with your head in your hands because you absolutely ruined a file and hit save.  I'm basically going to tell you to use version control for stuff that matters, but rather than letting you figure out how to do that, I'm simply going to straight up tell you.&lt;/p&gt;
&lt;h2 id="what-do-i-need-version-control-for-i-don-t-program"&gt;What do I need version control for, I don't program&lt;/h2&gt;
&lt;p&gt;Who cares about programming? Do you write text on your computer? Maybe Word docs? A personal web page? Blog entries as .txt files you'll copy-paste into wordpress later? It really doesn't matter: the real question is "do you have folders/directories with data in them that you change every now and then, and that you might mess up because you can accidentally hit save and overwrite them, or accidentally hit delete and lose them forever?".&lt;/p&gt;
&lt;p&gt;Because the answer is pretty much guaranteed "yes", and you could try to be diligent about never hitting save or delete, but you're human, and you're going to mess up. Maybe not today, maybe not next week, but chances are pretty much 100% at some point, you'll mess up.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;so use git&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="what-do-i-need-git-for-i-don-t-want-to-put-my-stuff-online"&gt;What do I need "git" for, I don't want to put my stuff online&lt;/h2&gt;
&lt;p&gt;Yeah, common misconception. "git" has nothing to do with "putting stuff online", but has everything to do with "being version control software". In order to be successful version control software, you need to be able to do remote syncing because the vast majority of version controlled data is collaborative data, but it's 100% not necessary for the version control part, so here's what you do:&lt;/p&gt;
&lt;h2 id="safeguard-your-data-from-you-"&gt;Safeguard your data from &lt;em&gt;you&lt;/em&gt;&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;install &lt;a href="https://git-scm.com/downloads"&gt;git&lt;/a&gt;. It's a few clicks, just do it.&lt;/li&gt;
&lt;li&gt;For any dir/folder that holds a project you do work on, run "git init". If you are familiar with the command line, it's literally just &lt;code&gt;$&amp;gt; cd your/project/dir&lt;/code&gt; followed by &lt;code&gt;$&amp;gt; git init&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Awesome, you now have version control running for that dir/folder.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="okay-what-s-next-"&gt;Okay, what's next?&lt;/h2&gt;
&lt;p&gt;Every time you make changes to your files, even if you're not done but you made some headway on them and feel like now would be a good time to take a snapshot: take a snapshot!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;$&amp;gt; git add -A&lt;/code&gt; (tell git to look at &lt;em&gt;all&lt;/em&gt; the changes that were made since the last snapshot)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$&amp;gt; git commit -m "give your snapshot a name and/or description here"&lt;/code&gt; (include the quotes)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Done. No syncing with the internet, no complicated workflow stuff, just &lt;code&gt;git add&lt;/code&gt; to add all the changes, and then &lt;code&gt;git commit&lt;/code&gt; to commit the snapshot to the version history.&lt;/p&gt;
&lt;h2 id="okay-i-ve-done-that-and-then-a-few-minutes-later-i-ruined-all-my-files-what-now-"&gt;Okay, I've done that! And then a few minutes later I ruined all my files! What now!?!?!&lt;/h2&gt;
&lt;p&gt;Say you accidentally deleted the files you needed from your project dir, and then to make things worse you also saved empty files on top of that because your text editor spazzed out! Oh no! If you didn't have &lt;code&gt;git&lt;/code&gt; managing your version control, you'd be completely screwed!&lt;/p&gt;
&lt;p&gt;But you have git managing your snapshot history, and as long as you still have its &lt;code&gt;.git&lt;/code&gt; dir, what you just did is effectively insignificant: just tell git to restore your last snapshot:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$&amp;gt; git reset --hard&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;And done. All your files are back, in the state they were in during the last snapshot. Sure, you may have lost a few minutes of work, but between that and "I lost everything", I'm pretty sure we'd both pick the few minutes of work lost option.&lt;/p&gt;
&lt;h2 id="it-worked-but-then-i-messed-up-again-and-this-time-i-also-deleted-my-git-directory-"&gt;It worked! But then I messed up &lt;em&gt;again&lt;/em&gt; and this time I also deleted my &lt;code&gt;.git&lt;/code&gt; directory!!&lt;/h2&gt;
&lt;p&gt;That's the only way to make sure &lt;code&gt;git&lt;/code&gt; can't help you anymore. If your workflow is such that you &lt;em&gt;can&lt;/em&gt; delete entire directories, then really you need to get yourself some remote syncing/backup solution. That's kind of out of scope for this short post on "version control your stuff already, you are smart enough to understand the need for it", but you could look at things like &lt;a href="https://www.dropbox.com/"&gt;Dropbox&lt;/a&gt; and/or &lt;a href="https://www.backblaze.com"&gt;backblaze&lt;/a&gt;. If your work is that important, why are you not paying the $5/mo to properly protect &lt;em&gt;all the data on your computer&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;Also, if you have any kind of user account control, make sure to set the &lt;code&gt;.git&lt;/code&gt; directory (but not its content) to read-only, so that even if you accidentally try to delete it, your OS will go "hey you can't actually delete this dir, okay? you're going to have to unlock it before I can do that for you". Depending on your OS the way you do this differs, but again instead of telling you to look up how to do that, I'm just going to tell you.&lt;/p&gt;
&lt;p&gt;On Linux, Unix, and OSX, you can use the terminal to issue &lt;code&gt;$&amp;gt;chmod 0444 .git&lt;/code&gt; in your project's directory, which sets the permissions for the ".git" dir (but not its content) to read-only. Unless you're deleting things with &lt;code&gt;rm&lt;/code&gt;, that dir will be relatively safe now.&lt;/p&gt;
&lt;p&gt;On windows, use any filemanager and right click the dir's folder, and then make sure to check the "read-only" box. On windows deleting the .git dir is usually less of a problem because the dir's marked as "hidden". You'll see it if you're a power user who unhides system and hidden dirs/files, but in normal use you won't see it, and thus won't accidentally delete it.&lt;/p&gt;
&lt;h2 id="i-didn-t-actually-mess-anything-up-but-i-d-like-to-look-at-an-old-snapshot-"&gt;I didn't actually mess anything up, but I'd like to look at an old snapshot...&lt;/h2&gt;
&lt;p&gt;Yeah that's a thing you can do. You can scroll through your snapshot history by using &lt;code&gt;$&amp;gt; git log&lt;/code&gt;, which will tell show your the name/descriptions for each snapshot (which is why you want to at least use sensible naming/descriptions. A single dot is fast to write, but useless if you ever need to go through your history), tied to a git "commit hash", which is a long hexadecimal string that uniquely identifies that snapshot for the git application. Say I need last week's version of a novel I'm writing, because I rewrote half a chapter but I remember there was a paragraph that had super sweet phrasing and I want it back:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;$&amp;gt; git add -A&lt;/code&gt; because I don't want to lose any work&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$&amp;gt; git commit -m "midday work, somedate-2016"&lt;/code&gt; so that git has a snapshot for where I am right now.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$&amp;gt; git log&lt;/code&gt;, to see my history&lt;/li&gt;
&lt;li&gt;Notice that "end of day, Monday, week 2, 2016" has commit "dbcaf87689facb6bcb6f9eb786fs9".&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$&amp;gt;git checkout dbcaf87689facb6bcb6f9eb786fs9&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Boom, git changes everything to match what they were at the time I took that snapshot. I can copy the bits I need onto my desktop, then make sure to put me back on where I just was&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$&amp;gt; git reset master&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This changes all my files to where I just was again, and I can go on with my life. So handy!&lt;/p&gt;
&lt;h2 id="what-else-can-i-do-"&gt;What else can I do?&lt;/h2&gt;
&lt;p&gt;Quite a lot, but all of that's covered by &lt;a href="https://git-scm.com/book/en/v2"&gt;the git book&lt;/a&gt;, and a lot of it is mostly irrelevant unless you also want to do remote syncing of your data. Still, good read if you really care about your data.&lt;/p&gt;
&lt;h2 id="what-if-the-command-line-is-too-unfamiliar-to-me-"&gt;What if the command line is too unfamiliar to me?&lt;/h2&gt;
&lt;p&gt;You can use the &lt;code&gt;git-gui&lt;/code&gt; command. This will ask you (if you "just run it") whether to create a new repository, or manage an existing one. I'm not going to explain how to use that, because  I never use it, but it can do all the things this post talked about.&lt;/p&gt;
&lt;h1 id="that-s-it-we-re-done-"&gt;That's it, we're done.&lt;/h1&gt;
&lt;p&gt;Go use version control. You &lt;em&gt;litearlly&lt;/em&gt; have no excuse not to. And if you have any questions or comments, you can either leave those over on github (see the link below this post) or just tweet at me &lt;a href="http://twitter.com/TheRealPomax"&gt;@TheRealPomax&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Version control your files, because you shouldn't be able to be your own enemy.&lt;/p&gt;
</description>
<category>Git</category>
<category>Version Control</category>
<link>http://pomax.github.io/#gh-weblog-1453231679399</link>
<guid>http://pomax.github.io/#gh-weblog-1453231679399</guid>
<pubDate>Tue, 19 Jan 2016 19:27:59 GMT</pubDate>
</item>
<item>
<title> React with LaTeX, without needing client-side Mathjax</title>
<description>&lt;p&gt;It's no secret that I like working with &lt;a href="https://facebook.github.io/react"&gt;React&lt;/a&gt;, and that I like &lt;a href="https://en.wikipedia.org/wiki/LaTeX"&gt;LaTeX&lt;/a&gt; for my maths, and that I like &lt;a href="https://mathjax.org"&gt;MathJax&lt;/a&gt; for my LaTeX on the web. What I don't like, though, is having to wait 20 seconds for a long article with lots of maths to load client-side, constantly changing the page dimensions as it does so. Especially if you're loading it mid-page and then MathJax kicks in and all the content keeps being pushed down. And again. And again, etc. etc.&lt;/p&gt;
&lt;p&gt;It's annoying for the user, and as the guy who runs a &lt;a href="http://pomax.github.io/bezierinfo"&gt;big article on BÃ©zier curves&lt;/a&gt;, with lots of maths, it's annoying to know I'm responsible for a bad experience. So, I'm rewriting that article so that it's easier to maintain, and loads a million times faster. One of the things that involves is taking MathJax out of the client-side experience, which means during LaTeX conversion server-side. Or really, "offline", because it should be a "generate once, then cache and use" instead of "having the server generate it all the time".&lt;/p&gt;
&lt;h2 id="react-and-webpack-and-babel-"&gt;React and Webpack (and Babel)&lt;/h2&gt;
&lt;p&gt;First off, a React codebase needs bundling, and generally also some &lt;a href="https://facebook.github.io/react/docs/jsx-in-depth.html"&gt;JSX&lt;/a&gt; transforming and &lt;a href="https://babeljs.io/docs/learn-es2015"&gt;ES2015+&lt;/a&gt; conversion, so the basis for my rewrite was a fairly simple dir layout with a fairly simple &lt;a href="https://webpack.github.io"&gt;Webpack&lt;/a&gt; config:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./
 |-&amp;lt;components&amp;gt;
 |-&amp;lt;images&amp;gt;
 |-&amp;lt;lib&amp;gt; 
 |-&amp;lt;stylesheets&amp;gt;
 | package.json
 | webpack.config.js
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the Webpack config doing the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var webpack = require('webpack');

// Hot Reload server when we're in dev mode, otherwise build it the normal way.
var entry = ['./components/App.jsx'];
if(!process.argv.indexOf("--prod")) { entry.push('webpack/hot/dev-server'); }

module.exports = {
  entry:  entry,
  output: {
    path: __dirname,
    filename: 'article.js'
  },
  module: {
    loaders: [
      { test: /\.(png|gif)$/, loader: "file?name=images/packed/[hash].[ext]" },
      { test: /\.less$/, loader: "style!css!less" },
      { test: /.jsx?$/, include: /components/, loaders: ['babel-loader']
      }
    ]
  },
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is a pretty standard setup, with webpack's &lt;a href="https://webpack.github.io/docs/hot-module-replacement-with-webpack.html"&gt;"hot reloading" server&lt;/a&gt; for dev work, and no server for production builds. Running Webpack for production will yield a file &lt;code&gt;article.js&lt;/code&gt; in the root, based on starting at the &lt;code&gt;component/App.jsx&lt;/code&gt; file, and then just bundling in every little requirement that has until we run out of things that need to be bundled in.&lt;/p&gt;
&lt;p&gt;You can see I'm using &lt;a href="http://babeljs.io"&gt;Babel&lt;/a&gt; for interpreting any js/jsx files (it takes care of JSX transforming and ES2015 syntax), as well as &lt;a href="http://lesscss.org"&gt;less&lt;/a&gt; for my CSS. There's also a dumb &lt;a href="https://www.npmjs.com/package/file-loader"&gt;"file-loader"&lt;/a&gt; which simply copies images into their own dir. Not always necessary, but useful when running the webpack dev server.&lt;/p&gt;
&lt;p&gt;The way I trigger either dev or prod runs is via &lt;a href="http://www.slideshare.net/k88hudson/advanced-frontend-automation-with-npm-scripts"&gt;npm scripts&lt;/a&gt;, with the &lt;code&gt;package.json&lt;/code&gt; using the following script block:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  ...
  "scripts": {
    "build": "webpack --prod",
    "start": "webpack-dev-server --progress --colors --hot --inline",
  },
  ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Two commands, a short &lt;code&gt;$&amp;gt; npm start&lt;/code&gt; for dev work, since that gets run all the time, and a special &lt;code&gt;$&amp;gt; npm run build&lt;/code&gt; for when the production bundle needs to be built. So far so good!&lt;/p&gt;
&lt;h2 id="adding-latex-to-react-components"&gt;Adding LaTeX to React components&lt;/h2&gt;
&lt;p&gt;One thing I hate when doing rewrites is "changing everything" to suit the technology. The article as it exists relies on LaTeX that takes the following form:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;p&amp;gt;\[
  f(x) = \sum^n_{k=0} \frac{n(n-k)}{k! + x} 
\]&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That's a pretty standard format if you use MathJax, or &lt;a href="https://github.com/Khan/KaTeX"&gt;KaTeX&lt;/a&gt;, and since I use a &lt;em&gt;lot&lt;/em&gt; of LaTeX, that format had to stay. And that's a bit of a problem, because LaTeX uses a lot of curly brackets. And React's JSX syntax treats curly brackets as templating delimiters.&lt;/p&gt;
&lt;p&gt;Something like this, for instance:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;p&amp;gt;\[
  \frac{percentage}{100}
\]&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;will cause the JSX transform step to go "uh, I don't know a variable &lt;code&gt;percentage&lt;/code&gt;, I can't convert this for you". Even though we don't want it converted. Too bad for us! However, there is a way out, and it's called a Webpack loader.&lt;/p&gt;
&lt;h2 id="webpack-and-mathjax-node"&gt;Webpack and mathjax-node&lt;/h2&gt;
&lt;p&gt;You may have noticed the part where I mentioned Webpack uses babel for JSX and ES2015 transforms. That means it rewrites the source code several times before handing it off for bundling, and so if we can convert those LaTeX blocks before anything else tries to interpret it, things should work pretty well!&lt;/p&gt;
&lt;p&gt;So, let us write a latex-loader for Webpack. In fact, I've already done the work there, so, let's look at that. First off, Webpack &lt;strong&gt;is weird&lt;/strong&gt; when it comes to loader order, and uses a &lt;a href="https://en.wikipedia.org/wiki/Stack_%28abstract_data_type%29"&gt;LIFO&lt;/a&gt; ordering. The last loader gets to run first. So:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;loaders: [
  ...
  {
    test: /.jsx?$/,
    include: /components/,
    loaders: [
      'babel-loader',
      __dirname + '/lib/latex-loader'
    ]
  }
]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With a corresponding &lt;code&gt;latex-loader.js&lt;/code&gt; in the &lt;code&gt;./lib&lt;/code&gt; dir:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var op = "\\[";
var ed = "\\]";

/**
 * Is there going to be anything to convert here?
 */
function hasLaTeX(input) {
  return input.indexOf(op) !== -1 &amp;amp;&amp;amp; input.indexOf(ed) !== -1;
}

/**
 * We look for MathJax/KaTeX style data, and convert it to something JSX-safe 
 */
function escapeBlockLaTeX(source) {
  // MAGIC HAPPENS HERE!
  return doTheMagic(source);
}

module.exports = function(source) {
  this.cacheable();
  if (!hasLaTeX(source)) return source;
  return escapeBlockLaTeX(source);
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That's the main gist of it, anyway. The loader's basically a single synchronous function that gets passed entire files as source string, and then expects a possible different string as replacement output.&lt;/p&gt;
&lt;p&gt;So, the approach is obvious: accept the source only if it has LaTeX that needs transforming (otherwise just hand the original source back as a thing we don't need to change), and then if we're still running, find all the LaTeX blocks, transform them to "something safe", and then return that modified source. Ideally, transform them using MathJax.&lt;/p&gt;
&lt;p&gt;As it turns out, MathJax has a server-side library available called &lt;a href="https://www.npmjs.com/package/mathjax-node"&gt;mathjax-node&lt;/a&gt;, which can be used to generate browser-agnostic SVG or MathML source, so that's perfect! It means we can do the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var mathjax = require("mathjax-node");

function escapeBlockLaTeX(source) {
  var from = 0, curr, term, newsource = "", latex;
  for(curr = source.indexOf(op, from);
      curr !== -1;
      from = term + ed.length, curr = source.indexOf(op, from))
  {
    // split out a block of LaTeX:
    newsource += source.substring(from, curr);
    term = source.indexOf(ed, from);
    if(term === -1) {
      // We only have ourselves to blame if we get here
      throw new Error("improperly closed LaTeX encountered!");
    }
    latex = source.substring(curr, term + ed.length);

    // convert this LaTeX code to SVG, which React can deal with just fine:
    var mathjaxed = mathjax.typeset(latex);

    // slot the SVG code in place of the LaTeX code
    newsource += mathjaxed;
  }
  return newsource + source.substring(from);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Except... we can't.&lt;/p&gt;
&lt;h2 id="webpack-mathjax-and-the-problem-of-sync-vs-async"&gt;Webpack, MathJax, and the problem of sync vs. async&lt;/h2&gt;
&lt;p&gt;You see, Webpack is a fully synchronous technology. A loader gets a file, transforms it, then passes it back to webpack, which hands it to the next loader, which transforms it, and so on. This is a fully synchronous process, and loaders simply get data, and "immediately" (give or take the time needed to modify that data) give something back.&lt;/p&gt;
&lt;p&gt;MathJax can't do that. It relies on quite a few asynchronous things (like font loads), and so where webpack has a function API much like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;module.exports = function webpackloader(input) {
  return formOutput(input);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;MathJax has a function API like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mathjax.typeset(input, function(result) {
  if(!result.errors) {
    doSomethingWith(result.svg);
  }
});
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That doesn't look too strange, &lt;a href="http://stackoverflow.com/questions/748175/asynchronous-vs-synchronous-execution-what-does-it-really-mean"&gt;but the timing is crucially different&lt;/a&gt;: when the Webpack loader runs, its function is entered, data is transformed, and it exits again. However, when the MathJax typesetter runs, the function call happens and then &lt;em&gt;immediately exits again&lt;/em&gt;, and at some point in the future the result handling function will run, and there is no way to "wait" for it to finish, because that's not a thing JavaScript can do.&lt;/p&gt;
&lt;p&gt;If only there was a way that we could turn the asynchronouse conversion process that MathJax requires, into a synchronous data transform as is required by Webpack...&lt;/p&gt;
&lt;h2 id="execsync-ing-our-way-to-success"&gt;execSync'ing our way to success&lt;/h2&gt;
&lt;p&gt;And in that wish we find the answer: make the conversion a command line utility, and then &lt;code&gt;exec&lt;/code&gt; that utility synchronously, using &lt;a href="https://nodejs.org"&gt;Node.js&lt;/a&gt;'s built in &lt;a href="https://nodejs.org/api/child_process.html#child_process_child_process_execsync_command_options"&gt;execSync&lt;/a&gt;, because the following will work brilliantly:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var execSync = require("child_process").execSync;

function escapeBlockLaTeX(source) {
  ...
  for(...) {
    // split out a block of LaTeX:
    latex = ...

    // convert all this!
    var mathjaxed = execSync("node tex2svg.js --latex " + latex);

    // slot the rewritten code back in
    newsource += mathjaxed;
  }
  ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We write a simple &lt;code&gt;tex2svg.js&lt;/code&gt; file that requires &lt;code&gt;mathjax-node&lt;/code&gt;, passes it the config options for conversion to SVG, read in the LaTeX as command line argument, and then spits out the conversion result on &lt;a href="https://en.wikipedia.org/wiki/Standard_streams"&gt;standard out&lt;/a&gt;, so that &lt;code&gt;execSync&lt;/code&gt; treats it as its function return value.&lt;/p&gt;
&lt;p&gt;But here's where things get tricky. Writing a command line utility that does the MathJax conversion requires a little work, because the command line is tricky, and LaTeX contains all kinds of characters that can do things in shell land. Slashes and ampersands abound, and those are kind of active symbols,  so we need to be a little smarter:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// convert all this... smarter!
var base64 = new Buffer(latex).toString("base64");
var mathjaxed = execSync("node tex2svg.js --base64 " + base64);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then we just need to make sure that the MathJax script unpacks the passed data from &lt;a href="https://en.wikipedia.org/wiki/Base64"&gt;base 64 format&lt;/a&gt; to plain string format before converting, and we're good!&lt;/p&gt;
&lt;p&gt;But not quite: this is not exactly a cheap thing to do. Firing up an instance of node and loading &lt;code&gt;mathjax-node&lt;/code&gt; takes time. Not enough to notice if you only do it once, but if you need to run this lots of times, a second each time adds up to having to wait minutes for this building to happen. Every time you want to run the dev server.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;That is unacceptable.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So, let's add in some caching: instead of having the MathJax script do the conversion for us, and then spit out the SVG code, we make it do the conversion but then write the SVG code to file, in the images dir.&lt;/p&gt;
&lt;p&gt;And because we don't want the build process to do more work than necessary, we make the filenames predictable, based on the LaTeX that needs to be converted: we compute the &lt;a href="https://en.wikipedia.org/wiki/SHA-1"&gt;sha1 digest&lt;/a&gt; of the LaTeX that needs converting, and only if we don't see a file called &lt;code&gt;&amp;lt;hash&amp;gt;.svg&lt;/code&gt; in the images dir do we do our conversion:  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;var sha1 = require("sha1");

function escapeBlockLaTeX(source) {
  ...
  for(...) {
    latex = ...;

    // Get the digest for the latex - any subsequent checks for the same block
    // of LaTeX will yield the exact same digest, which is handy!
    var hash = sha1.hash(latex);

    // Whether the SVG for this LaTeX already exists or not, we already know
    // the filename it's going to have, so we can prebuild the JSX we need:  
    var imgHTML = '&amp;lt;img src="' + hash + '.svg" className="LaTeX SVG"/&amp;gt;';

    // Then: do we need to generate this image first? If so, execSync,
    // otherwise we do absolutely nothing because we're already done!  
    if (!imageExists(hash)) {
      var base64 = new Buffer(latex).toString("base64");
      execSync("node tex2svg.js --hash " + hash +" --base64 " + base64);
    }

    newsource += imgHTML;
  }
  return newsource;
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And that, as they say, is that!&lt;/p&gt;
&lt;h2 id="boom-"&gt;Boom.&lt;/h2&gt;
&lt;p&gt;Using this latex-loader in conjunction with a file writing conversion utility script, we now have a &lt;em&gt;synchronous&lt;/em&gt; MathJax conversion going on, despite MathJax itself being an inherently asynchronous processor, and we completely bypass any strangeness that might normally pop up if you tried to mix LaTeX code and JSX syntax, with the benefit of files that can be cached, so that the browser doesn't need to redownload them everytime the article gets loaded in a browser.&lt;/p&gt;
&lt;p&gt;Responsiveness increase: x1 million. Goal reached.&lt;/p&gt;
&lt;p&gt;Instead of every individual user needing to wait for MathJax to do typesetting, the only person waiting for MathJax now is me, and only for "new" LaTeX blocks during the build step. &lt;em&gt;As it should be&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I can add sections one at a time, and every time I run the build step, only genuinely new LaTeX will need to get converted. LaTeX that got processed during a previous run already wrote files to disk, so the latex-loader just bypasses the conversion process entirely for those LaTeX blocks, and so the build really only does exactly as much work as it needs to do to get the data transformed.&lt;/p&gt;
&lt;p&gt;Needless to say, I am chuffed to bits about this, and if you have any questions about the process, feel free to reach out to me &lt;a href="https://twitter.com/TheRealPomax"&gt;on twitter&lt;/a&gt; or &lt;a href="https://github.com/Pomax/BezierInfo-2/issues"&gt;on github&lt;/a&gt;, and I'll be happy to talk about it more.&lt;/p&gt;
</description>
<category>React</category>
<category>LaTeX</category>
<category>MathJax</category>
<category>Webpack</category>
<link>http://pomax.github.io/#gh-weblog-1451617530567</link>
<guid>http://pomax.github.io/#gh-weblog-1451617530567</guid>
<pubDate>Fri, 01 Jan 2016 03:05:30 GMT</pubDate>
</item>
<item>
<title> Developing Open Source Software</title>
<description>&lt;p&gt;I want to take a little bit of time to explain how I work on Open Source, both privately and as part of my job as a Software Engineer at the Mozilla Foundation. Not because it's wildly different from how everyone else does it, but because it's probably the same as how the vast majority works on Open Source, which means very few people bother to explain the processes involved.&lt;/p&gt;
&lt;p&gt;There are two different kinds of "working on open source", depending on whether the code is a collaboration or just a simple one-person project, so let's look at both.&lt;/p&gt;
&lt;h2 id="-i-m-making-a-thing-"&gt;&lt;em&gt;"I'm making a thing!"&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;If you're making a thing, the basic rule is "anything goes": you're the only one you're inconveniencing by taking shortcuts, and often that's fine. However, if you're starting a project that you think might at some point gain contributors (say, you're making a thing that you hope becomes popular), there are a few things you can do to make sure that when your project does go from "one dev" to "a team", the transition is smooth:&lt;/p&gt;
&lt;h3 id="file-issues-before-fixing-them"&gt;File issues before fixing them&lt;/h3&gt;
&lt;p&gt;Not only is it a handy If you file the issues you know about as a kind of to-do list to walk through, but you might be surprised to find someone actually fixing an issue you filed before you get to it, once your project gets even a little exposure.&lt;/p&gt;
&lt;h3 id="work-in-branches-"&gt;Work in branches.&lt;/h3&gt;
&lt;p&gt;There will be an initial "I just need to get this code written" period where you're pushing to master: awesome, go for it. However, once you reach what might turn into a 1.0 with a bit more code, start getting in the habit of treating your master branch as off limits, and working in branches that you merge into master instead. This makes it easier for contributors to do the same.&lt;/p&gt;
&lt;h3 id="document-document-document-"&gt;Document, document, document.&lt;/h3&gt;
&lt;p&gt;You're not actually working on your code alone: you're collaborating with your future self, and future self has no idea what you're thinking right now while you're writing your code: document your choices, explain complex bits of code and whatever you do, explain hacks and bodges! Clever as they might be today, 2 months from now they might be so clever you actually need to spend your own time on them to figure out why they even work the way they do. Help future-you out: write documentation.&lt;/p&gt;
&lt;p&gt;And that doesn't need to be wikis or long readmes, it can just be code comments: as long as knowledge you need to understand changes you're making right now isn't lost, you're being awesome. &lt;/p&gt;
&lt;h2 id="-we-re-making-a-thing-"&gt;&lt;em&gt;We're making a thing.&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;While you're fairly free to do what you want to do on your own, for collaborative projects, there is really only one way to work in a way that's not going to break down. For anything that needs to be done, follow the three F's:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;File it&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fix it&lt;/strong&gt;, and&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Follow up&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="1-file-it-"&gt;1) File it!&lt;/h3&gt;
&lt;p&gt;If you're going to work on something, make sure it's a known issue. Code changes without an issue that explain why the changes were necessary in the first place are mystery changes, and mysteries in a collaborative effort are bad.&lt;/p&gt;
&lt;p&gt;However, that doesn't mean the changes aren't necessary, so: always, &lt;strong&gt;always&lt;/strong&gt; make sure there's a ticket, or issue, or bug report, associated with the changes you're making, so that your code changes can say "this fixes/addresses ticket/issue/bug so-and-so". Sometimes those tickets/issues/bug reports already exist and you can simply refer to them, but sometimes they don't: &lt;strong&gt;file it before submitting your code changes&lt;/strong&gt;, so that you can refer to that newly filed ticket.&lt;/p&gt;
&lt;p&gt;It's okay to already have the code in place that addresses an issue you haven't filed yet, just make sure that by the time you submit your changes, there is one.&lt;/p&gt;
&lt;p&gt;Collaboration relies on communication. If people change the code without tying it to the list of "these are issues we need to address", then there is no way to track changes in the codebase. Generating a changelog based on closed issues is often quite easy, but if there are no issues that got closed/resolved due to changes getting accepted into the code base, then you're asking people to work on code that potentially no one can explain (because the person who contributed it may have left already. If you can even track who submitted the change at all).&lt;/p&gt;
&lt;p&gt;Also, &lt;strong&gt;file individual issues&lt;/strong&gt;. The best code bases are ones where each thing that needs to be done is filed separately, and fixed separately, because it's much easier to work on as a team (small tasks make for rapid progress), and it makes it easy to track complex tasks: if you need to implement a user profile system, and that requires a login system, a user database, and user facing UI, then if someone files "implement a user profile system", the very first thing that should happen is chopping that issue up into several smaller issues. It might sound anal, but you're working in a team, and many hands make light work: the smaller you can chop up an issue, the easier it becomes to resolve the bigger task.&lt;/p&gt;
&lt;h3 id="2-fix-it-"&gt;2) Fix it...&lt;/h3&gt;
&lt;p&gt;Crazy as it may sound: never start fixing things by writing code. First ask: "Has someone else already written the code and can I just plug that in?". If they have: just use that. You're still probably going to need a little bit of code to do the "plugging it in" part, but little bits of code are easy to maintain, and it means you're not responsible for maintaining lots of code.&lt;/p&gt;
&lt;p&gt;Conversely, if there is no code out there that already does what you need to do, ask yourself: "Can I write this as a standalone utility, and then plug &lt;em&gt;that&lt;/em&gt; in?". Because if you can, that's worth doing. If you need to solve a problem and there's no solution out there, you're probably solving a problem that other people are also having: it's worth making that solution available.&lt;/p&gt;
&lt;p&gt;Of course, there will be plenty of issues that can only be addressed by writing real, project-relevant, code, and for those occasions there are three things to keep in mind:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;commit early&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;commit often&lt;/strong&gt;, and&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;communicate with your team&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="commit-early"&gt;Commit early&lt;/h4&gt;
&lt;p&gt;If you're working on code changes, push up your changes as soon as you have "something" going. &lt;strong&gt;Especially if it's not done yet&lt;/strong&gt;. Don't wait until "it's done", because you have no idea when that will be: form a commit and push it up once you have the basic stubs in place, for instance, before you start working out the code in full.&lt;/p&gt;
&lt;p&gt;This lets other people that work with you see what you're working on, and lets them catch things early that would cost a lot of time to fix later on. &lt;/p&gt;
&lt;h4 id="commit-often"&gt;Commit often&lt;/h4&gt;
&lt;p&gt;Some code changes are one liners or a simple function renaming, but many are not: don't wait until you're done to push up your changes. Any time you write some code and test it, and it passes, that's a moment to form a commit, push it up, and then keep going.&lt;/p&gt;
&lt;p&gt;If a computer dies (and if you work in a team, that will happen surprisingly often) or someone unexpectedly becomes unavailable for a few days (again, happens more often than you might think), there is no loss of work &lt;strong&gt;for the team&lt;/strong&gt;. The team as a whole can pick up where you as a person left off in these circumstances, and if you don't commit often, they'll potentially have to reinvent changes you had already written.&lt;/p&gt;
&lt;p&gt;It's also much easier to rebase your code if they're small incremental commits when the master code base changes. For instance, a dependency got updated, which caused some functions to use that dependency's new API calls; that is much easier to deal with if it just requires you to change the small commit that touched a file for which that was the case than if you have one massive commit.&lt;/p&gt;
&lt;p&gt;Additionally, the more often you commit, the earlier possible bugs can be found; the earlier bugs are found, the less work it is to fix them, because not a lot of things will trigger them yet.&lt;/p&gt;
&lt;h4 id="communicate-with-your-team"&gt;Communicate with your team&lt;/h4&gt;
&lt;p&gt;If you're working on anything even moderately sized: start talking about your code with team members early. Don't ask them to review only all the way at the end if your changes involve new code or new approaches; run it by someone so that even if you're the only one that'll end up writing code, you're &lt;em&gt;not&lt;/em&gt; the only one who knows what decisions were made while the code was being written.&lt;/p&gt;
&lt;p&gt;Also, remember to ask questions in the open. You might end up with blocking questions that need an answer before you can continue your work, and while it's tempting to try to find someone to get it answered in real-time, &lt;strong&gt;file it first&lt;/strong&gt;, so that the entire team can see it. Then you can find someone to real-time answer it and capture the answer in the filed issue, so that the entire team can be aware of the question having come up, and the answer that was agreed on.&lt;/p&gt;
&lt;h4 id="corrolary-know-when-to-split-your-work-"&gt;Corrolary: know when to split your work.&lt;/h4&gt;
&lt;p&gt;Some issues reveal problems in other parts of the project, and you might be tempted to fix those as part of your changes. I know it's tempting, but &lt;strong&gt;don't&lt;/strong&gt;, because you're not actually helping the team that way. Instead: file it, fix it, and follow up.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Step away from the current code when you reach a good break point (and that could be immediately, if the thing you found is blocking you),&lt;/li&gt;
&lt;li&gt;File the issue as a new issue,&lt;/li&gt;
&lt;li&gt;If it's blocking you:&lt;ol&gt;
&lt;li&gt;Fix it first,&lt;/li&gt;
&lt;li&gt;Schedule follow up&lt;/li&gt;
&lt;li&gt;Rebase your code on the fix, so you're unblocked&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Now you can come back to the code you were already working on.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You'll note that in step 3 the advice is to work on it immediately only if it's actually blocking you: this is important. You're working in a team, and someone else might have a free moment to work on the thing you just discovered, while you keep working on your own changes.&lt;/p&gt;
&lt;h3 id="3-run-through-the-follow-up-"&gt;3) Run through the follow-up.&lt;/h3&gt;
&lt;p&gt;You've worked on code changes, you committed early, and often, and your "patch" now consists of 12 commits and two observations about future work: it's time for follow-up.&lt;/p&gt;
&lt;h4 id="clean-up-your-code"&gt;Clean up your code&lt;/h4&gt;
&lt;p&gt;If your changes work using 12 commits, then your changes work, and it's time to squash those 12 commits into a single commit so it can be landed into the codebase without all the steps that got you there. Even if there is no requirement to squash your code before landing, changelog generation, revision control, and rollbacks are all much nicer if patches land as single commits.&lt;/p&gt;
&lt;p&gt;Also, if there are any unnecessary comments or logs/prints in your code, now's the time to get rid of those, and of course, now is also the time to make sure that any missing documentation either gets added, or gets filed as "document XYZ", to be worked on immediately after landing your changes, rather than anything else, which brings us to...&lt;/p&gt;
&lt;h4 id="file-anything-you-found-but-didn-t-fix-"&gt;File anything you found, but didn't fix.&lt;/h4&gt;
&lt;p&gt;While you were working on your changes, you may have thought of things that might need addressing outside of the changes you made: &lt;strong&gt;file those&lt;/strong&gt;. It is important to capture those observations in a way that the entire team can see them.&lt;/p&gt;
&lt;h4 id="talk-to-your-team"&gt;Talk to your team&lt;/h4&gt;
&lt;p&gt;Finally, follow up with people, too. Let the people who need to know about your changes know about your changes - ask them to review you patch, explain your work to them where needed, if there is testing involved, make sure they understand what needs to be done, and generally make sure at least two people agree these changes are good to go (including yourself). That communication doesn't need to happen in person, the issue tracker you use might facilitate this kind of follow up, but always collaborate on the landing, even if the code works. There might be last minute changes or decisions that you were not aware of that someone else might: good to discover that before the changes are merged in!&lt;/p&gt;
&lt;h2 id="that-s-pretty-much-it"&gt;That's pretty much it&lt;/h2&gt;
&lt;p&gt;There's a fair amount of finer detail and variation that fits into the "file it, fix it, follow up" process, but stick to that order and you're on the path of a sustainable development cycle.&lt;/p&gt;
&lt;p&gt;Most of this is probably obvious to most people, but that just makes it all the more important to get it written down, because someone's going to be a bit bewildered and they'll need a blog post to get them on track =)&lt;/p&gt;
</description>
<category>Open source</category>
<category>Development</category>
<category>Process</category>
<category>Mozilla</category>
<link>http://pomax.github.io/#gh-weblog-1450207129290</link>
<guid>http://pomax.github.io/#gh-weblog-1450207129290</guid>
<pubDate>Tue, 15 Dec 2015 19:18:49 GMT</pubDate>
</item>
<item>
<title> OpenType: let's learn how modern fonts actually work</title>
<description>&lt;p&gt;In a previous post &lt;a href="/1449438115186"&gt;I talked about the distinction between "TTF" and "OTF" fonts&lt;/a&gt;, and the fact that they're actually both just OpenType fonts. I explained how the difference between TTF and OTF is only which outline language is used, with everything else being the same between the two types of Opentype font, so in this post I'd like to talk about some of the bits that all OpenType fonts have. There are actually quite a lot of things, so this will not be the last post on the subject, but let's just cover as much as we can and see what that leaves.&lt;/p&gt;
&lt;p&gt;Let's start with something that might sound like it can't possibly be true:&lt;/p&gt;
&lt;h2 id="fonts-don-t-contain-letters-"&gt;Fonts don't contain letters.&lt;/h2&gt;
&lt;p&gt;I know this sounds a bit weird for a technology that is supposed to be used to draw letters, but it's important to get this out of the way first: fonts don't know anything about "letters". Instead, they know about character codes, and glyphs. Character codes are simply numbers that the computer sees when you type, when it reads a text file, etc. and glyphs are anything in the font "that can be drawn". A font is a collection of inherently meaningless pictures, linked to character codes to give them meaning.&lt;/p&gt;
&lt;h3 id="the-problem-with-defining-letters-"&gt;The problem with defining "letters"&lt;/h3&gt;
&lt;p&gt;The reason fonts contain character codes and glyphs, rather than "letters" is that letters are a very restricted class of things we write. For instance, clearly the "letters" a through z are letters; this is true by definition. But are numbers letters? We can say that Fonts contain numbers and letters, but then what about symbols? Okay, fonts contain numbers, letters, and symbols. Clearly we're done. But what about CJK languages? Their writing systems don't use "letters": Korean has syllables, instead, Chinese has logograms, and Japanese uses both. So now things are getting very tricky. But let's make it even more fun: let's look at different kinds of the same letter. In English, the 'a' and the 'A' are both the same letter, as well as different letters. If you had to group the elements of a set "a,a,A,a,a,A,A,b,A,b,b,a,B,B,B", you would probably group them as a's in one pile, and b's in another. But if you had to group a full mixture of the alphabet in upper and lowercase, you'd probably sort them according to case. Are they the same letter or different letters? What about Arabic, in which each letter has four possible shapes depending on where in a word it's used (a letter will look different depending on whether it's on its own, or at the start of, middle of, or end of a word). What about those, are those all different letters, or the same one?&lt;/p&gt;
&lt;p&gt;So in order to get around this problem, fonts don't contain letters. They contain &lt;a href="https://en.wikipedia.org/wiki/Glyph"&gt;glyphs&lt;/a&gt;: anything that you can draw an outline for can be made a glyph, so that in a font: yes, all those different forms of the same thing are different things, and it's up to the character mapping and substitution rules specified in the Opentype font to determine which glyph should be used when.&lt;/p&gt;
&lt;h3 id="character-code-sets"&gt;Character code sets&lt;/h3&gt;
&lt;p&gt;So where do the character mappings come from? How many are there? Which are "the best"?&lt;/p&gt;
&lt;p&gt;For convenience, I'm going to ignore a &lt;em&gt;lot&lt;/em&gt; of history, mostly because you can write full chapters on the history of character mappings, and we'd still not get to where I want to get in this post, so: lots of different people and organisations have coined lots of different character mappings throughout the history of computing, and of those, I want to focus on two major ones: ASCII, and Unicode.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/ASCII"&gt;ASCII&lt;/a&gt; is probably the oldest, still widely used, standard, and it was invented to capture the symbols used in American computing, using 7 bits. Because back in the day, there weren't necessarily 8 bits to a byte, sometimes you have 7, or 6, or some other value that we now think of as weirdly "not eight". Anyway, ASCII uses 7 bits, and so there are 128 possible codes available: 0 through 127. The first 32 codes are "control" codes, not so much related to typing things as controlling the computer: escape, backspace, tabulation, line feed, data acknowledgement, things that control what the computer will do. After that are the numbers, letters, and symbols that were commonly (and a few uncommonly) used in American computing environments, and the very last code is the "delete" code.&lt;/p&gt;
&lt;p&gt;Of course, at the same time the rest of the world was inventing tons of other encodings because America wasn't the only country in the world using computers, and as the world became more and more connected, the more we had problems around trying to read text written by someone who wasn't using the same encoding, as well as needing way more than just 128 "spots" to capture all the different things necessary for each language, let alone "all languages".&lt;/p&gt;
&lt;p&gt;And that's where &lt;a href="https://en.wikipedia.org/wiki/Unicode"&gt;Unicode&lt;/a&gt; comes in: Unicode was, and remains, our best effort to fit all writing systems in this world into a single character mapping. As you can imagine, that mapping is huge: over 120,000 codes at this point in history (in June 2015, the Unicode standard v8 was released). But: the standard is public, it's stable (meaning that it's never going to fix historical mistakes like two different codes that point to the same character, but that no one noticed before accepting the code into the standard), and it takes a fairly long time to get new codes assigned specifically to make sure that standard doesn't "just grow" as we add more and more languages into it, but actually has some internal logic that computer scientists, programmers, etc. can rely on.&lt;/p&gt;
&lt;p&gt;The one thing that made switching to Unicode even possible, was that the first 128 codes in Unicode are, in fact, the ASCII codes, which made it possible to switch from ASCII to Unicode with virtually no effort. ASCII data, in an 8 bit world, is automatically data that matches the Unicode mappings, "encoded using the UTF-8 scheme".&lt;/p&gt;
&lt;h3 id="byte-encodings"&gt;Byte encodings&lt;/h3&gt;
&lt;p&gt;If you have a standard that contains way more numbers than fit in 8 bits, you need an extra step to turn possibly huge numbers into sequences of bits. Where ASCII is both the character code set and the encoding, Unicode needs a bit more work: it is only the character code set, and in order to write those codes as bytes on a disk, it has various "byte encoding" schemes available. All of these encode "Unicode data", but byte patterns on the disk can look radically different.&lt;/p&gt;
&lt;p&gt;The two common encodings for Unicode are things you've probably heard of, even if you don't know what they are exactly: UTF-8, or UTF-16. For details on both, wikipedia is a great source of information, so I will just summarise them here.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/UTF-16"&gt;UTF-16&lt;/a&gt; simply "tried" to capture every code using 16 bits, and then when there were so many codes that it became obvious that 16 bits would not be enough, a special few codes were reserved for "if you see this code, it's actually not a character mapping itself, but has to be combined with the &lt;em&gt;next&lt;/em&gt; 16 bits to form one of the higher numbers that don't fit in 16 bits".&lt;/p&gt;
&lt;p&gt;From this description, you'd imagine that &lt;a href="https://en.wikipedia.org/wiki/UTF-8"&gt;UTF-8&lt;/a&gt; does something similar, and it totally does, except it's generally far more efficient than UTF-16 in how it does it; UTF-8 is a variable byte encoding, with marker bits to say how many bytes are used, and whether a byte is a "start" byte or a follow-up byte. It matches ASCII byte-for-byte by starting with the bit 0 ("there are no next bytes") and then the 7 bit ASCII value. For any value larger than 128, needing more than 1 byte, the first byte starts as 1,1,0 if there are going to be 2 bytes used, 1,1,1,0 for three, 1,1,1,1,0 for four, etc. Any subsequent byte starts with 1,0 (so if you pick a random spot in a UTF-8 stream, and you see a byte that starts as 1,0 you know you need to move forward or backward a little so you're not in the middle of a character's code representation).&lt;/p&gt;
&lt;h3 id="from-code-sets-to-glyphs"&gt;from code sets to glyphs&lt;/h3&gt;
&lt;p&gt;So on the conceptual side, we have "things you can write", which we capture as glyphs in a font, and a character mapping that assigns each of those things a number, but then we still have a problem: fonts don't have to implement every possible character, so if we look at the character mappings that are actually &lt;em&gt;used&lt;/em&gt; in a font, there might be lots of disjointed sets of supported, and not supported mappings.&lt;/p&gt;
&lt;p&gt;Fonts, on the other hand, are relatively efficient in how they store glyphs: they use arrays. The first glyph is in spot 0, the second glyph is in spot 1, the third in spot 2, and so forth: they are a stored in a list without gaps, and their ordering in that list is not related to any encoding or character mapping. It's just a list of pictures with ids derived directly from their position in the list.&lt;/p&gt;
&lt;p&gt;So even if we have our list of glyphs, and we know which character mapping our font will work with, and we know which parts of that mapping the font will support, we still need one more step to make sure we can look up with character code maps to which position in the font's list of glyphs.&lt;/p&gt;
&lt;h3 id="-internal-glyphs"&gt;"internal" glyphs&lt;/h3&gt;
&lt;p&gt;Finally, there can also be glyphs that don't map to character codes. This sounds a bit odd, because how would you ever see them, but glyphs don't need to specify all the outline data in a giant wad of instructions: they can also contain references to other glyphs. For instance, the Japanese character æ¾ (pine tree) and æ¿ (persimmon) have the same "drawing" on the left side. We can store that particular outline as an internal glyph, with its own glyph id, and then form those two characters by starting each off as saying "place the glyph at id ... on the left" before explicitly specifying the outlines for the rest of the glyph.&lt;/p&gt;
&lt;p&gt;As such, a font kind of &lt;em&gt;can&lt;/em&gt; contain gaps in the list of glyphs, not by having "nothing" in the list in some spots, but by having glyphs that don't have a mapping to any character code. Things can get really tricky!&lt;/p&gt;
&lt;h2 id="the-cmap-table"&gt;The CMAP Table&lt;/h2&gt;
&lt;p&gt;At this point you might think: "...but there are so many encodings and character mappings and no rules on how to order glyphs in that list, there must be millions of ways for that final mapping to look!" And you're not wrong. There really are an incredible number of "character code to font-internal glyph id" mappings that could exist, and so OpenType comes with not just one, but several different ways to set up a "character to glyph id" mapping, based on a few things like "does the font implement one, or multiple, sets of character codes", "can there be gaps in the sets or not", "are any of the sets not commonly implemented sets", etc. By answering these questions, you can find the best charcode to id mapping for what your font will support, and then based on that you can follow a small number of rules around how to order the glyphs in the list of glyphs so that everything will work efficiently.&lt;/p&gt;
&lt;p&gt;The thing that makes this work in OpenType fonts is called the &lt;a href="https://www.microsoft.com/typography/otspec/cmap.htm"&gt;&lt;code&gt;CMAP&lt;/code&gt;&lt;/a&gt; table, and if you're still thinking "wait, that sounds like still not enough to capture all those possibilities", you're still right, and OpenType lets you specify &lt;em&gt;multiple&lt;/em&gt; CMAP subtables, which can all be different, to efficiently cover the entire range of supported characters in your font.&lt;/p&gt;
&lt;p&gt;While you might think that the pictures inside the font are the most important part of a font, in terms of how fonts &lt;em&gt;work&lt;/em&gt;, the CMAP is the absolutely most important part: if the outlines are missing, but we have a CMAP, at least the CMAP can tell us there are no pictures to work with, and if any of the OpenType metadata is missing, we might be rendering the text in a really weird way, but without a CMAP we don't even know what characters a font supports, or how to even get to any of the pictures we need to render text. Without a CMAP, a font is just a useless binary file.&lt;/p&gt;
&lt;p&gt;(And yes, historically there have been font formats that actually had outline data in one file, being the 'useless binary file', and a separate cmap file that you could load to give meaning to the 'useless data')&lt;/p&gt;
&lt;h2 id="substitutions"&gt;Substitutions&lt;/h2&gt;
&lt;p&gt;Finally, we need one more thing to deal with issues around "which glyph do we even use?" such as what we saw for Arabic: one letter, but depending on where in a word it is, it has to look different. Or closer to English: ligatures, where typing an 'f' followed by an 'i' tends to generate some shape fi that looks different, and is in fact a different glyph, from the separate letters.&lt;/p&gt;
&lt;p&gt;This is called "substitution", and is handled by a table called the &lt;a href="https://www.microsoft.com/typography/otspec/gsub.htm"&gt;&lt;code&gt;GSUB&lt;/code&gt;&lt;/a&gt; table. It allows various kinds of substitutions, with rules that can be different depending on the language or script the font has to style: substitution rules for English may not need to apply in Vietnamese, for instance. In order to deal with all kinds of substitutions, the GSUB table is &lt;a href="https://www.microsoft.com/typography/otspec/chapter2.htm"&gt;split up into several sections&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;scripts, which say which "language" the text is in&lt;/li&gt;
&lt;li&gt;features, which control when substitutions kick in (such as common ligatures, historical number forms, etc)&lt;/li&gt;
&lt;li&gt;lookups, which are the actual "A becomes B" rules.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To get a substitution set up, you need a lookup (to say which actual substitution has to happen), tied to a feature (which gives the typographical context for the lookup), tied to a script (which gives the linguistic context for the feature). All of these are many-to-many, so one feature could be used by multiple scripts, and one script can use multiple features (and then the same for features and lookup relations).&lt;/p&gt;
&lt;p&gt;Substitution lookups also come in various forms, so that there are special structions for one-for-one substitutions (like turning every full stop into a Japanese sentence end marker), many-for-one (like word to icon substitution), initial, medial, and final substitutions (for languages like Arabic) and the rather complicated "contextual substitution" which lets you define patterns in the text that have to be true for the substitution to kick in.&lt;/p&gt;
&lt;h2 id="wrapping-up"&gt;Wrapping up&lt;/h2&gt;
&lt;p&gt;While it's tempting to argue about TTF vs OTF, the thing that really drives a font is the CMAP. Hopefully you now understand the core concept for modern OpenType fonts a bit better, understanding how a font knows which characters it supports, and how it it maps what you type to what you see.&lt;/p&gt;
&lt;p&gt;In a next post I'll cover some more typographical concepts like kerning and positioning, as well as some of the finer nuances between TrueType and Type2 outlines, which work together with the pure OpenType data about those things.&lt;/p&gt;
&lt;p&gt;And if you have questions, or comments, do let me know by clicking the comment link below.&lt;/p&gt;
</description>
<category>Fonts</category>
<category>OpenType</category>
<category>CMAP</category>
<category>GSUB</category>
<category>TTF</category>
<category>OTF</category>
<link>http://pomax.github.io/#gh-weblog-1449777175633</link>
<guid>http://pomax.github.io/#gh-weblog-1449777175633</guid>
<pubDate>Thu, 10 Dec 2015 19:52:55 GMT</pubDate>
</item>
<item>
<title> OpenType: what's the difference between TTF and OTF??</title>
<description>&lt;p&gt;This is going to be a multiparter, because I've been trying to write this as a single long read and it's just not working. So as the first part in part of an OpenType series: ttf and otf... what's the difference?&lt;/p&gt;
&lt;h2 id="first-it-s-all-opentype"&gt;First, it's all OpenType&lt;/h2&gt;
&lt;p&gt;One thing that most people don't know is that both TTF and OTF font are &lt;a href="https://www.microsoft.com/typography/otspec/"&gt;OpenType fonts&lt;/a&gt;. OpenType is a binary format, with an open specification (i.e. it's free to implement codecs for, and you can sign up for the opentype mailing list and influence future versions), that contains outline data (for drawing letters), tons of metadata used for things ranging from typesetting to hardware memory management, and language-specific typesetting rules like contextual substitutions and positioning. &lt;/p&gt;
&lt;p&gt;When people talk about "TTF" or "OTF" what they really mean is "files that end in &lt;code&gt;.ttf&lt;/code&gt; and &lt;code&gt;.otf&lt;/code&gt;", and those are two kinds of OpenType font: fonts ending in &lt;code&gt;.ttf&lt;/code&gt; are generally OpenType fonts that use the glyf/loca data blocks, with &lt;a href="https://www.microsoft.com/en-us/Typography/SpecificationsOverview.aspx"&gt;"TrueType"&lt;/a&gt; outlines, whereas fonts ending in &lt;code&gt;.otf&lt;/code&gt; are OpenType fonts that use a &lt;a href="https://partners.adobe.com/public/developer/en/font/5176.CFF.pdf"&gt;CFF data block&lt;/a&gt;, with &lt;a href="https://partners.adobe.com/public/developer/en/font/5177.Type2.pdf"&gt;"Type2"&lt;/a&gt; outlines. So the difference is in the outline language used. Everything else is the same, and there's a &lt;em&gt;lot&lt;/em&gt; of "everything else" in an OpenType font.&lt;/p&gt;
&lt;p&gt;We're not going to look at all the fine differences between the two in this post, but let's look at the ones that are easy to talk about and already make a big difference:&lt;/p&gt;
&lt;h3 id="truetype-tiny-simple-and-hardcoded-hinting"&gt;TrueType - tiny, simple, and hardcoded hinting&lt;/h3&gt;
&lt;p&gt;TrueType outlines are incredibly straight forward: you get lines and &lt;a href="http://pomax.github.io/bezierinfo/#introduction"&gt;quadratic curves&lt;/a&gt;, and that's pretty much it. It's really easy to define shapes in, but the curves are "too" simple so you need quite a few of them. If you have decent design tool, that's mostly irrelevant, and the only thing you'll notice is that an OpenType font that uses TrueType outlines tends to be bigger than an OpenType font with Type2 outlines for the same shapes.&lt;/p&gt;
&lt;p&gt;The other way in which TrueType differs is in how &lt;a href="https://www.typotheque.com/articles/hinting"&gt;"hinting"&lt;/a&gt; works. Hinting is a mechanism to tell font engines "if you need to scale this outline down to fit in the font size we need, and that leads to weird sub pixel positioning, here's how you should resolve that:..." When using TrueType, the hinting is explicit: all the information is stored in the TrueType data, so a font engine can be "dumb" about hinting and simply do what the font tells it to. That makes TrueType, again, a little bigger compared to Type2, but taken together with the simplicity of the language means it's really easy for people to write parsers that do the right thing. Not a lot of instructions, and the hinting is in-font.&lt;/p&gt;
&lt;p&gt;(Although even then, hinting can go &lt;a href="http://www.rastertragedy.com/"&gt;terribly wrong&lt;/a&gt;, because it's an incredibly hard subject)&lt;/p&gt;
&lt;h3 id="type2-rich-complicated-and-only-hinted-"&gt;Type2 - rich, complicated, and "only" hinted.&lt;/h3&gt;
&lt;p&gt;On the other hand, the Type2 language is super rich, with lots of nuanced outline operations possible (including some 'if humans can tell this is gently curve, curve it, otherwise make this a flat line" instructions!), as well as supporting a small programming language that lets you do some amazing things... if the font engine that's rendering the font supports them. Because most of them don't: Type2 supports lines and cubic curves, and these are generally supported by font engines, but they also support more esoteric operations that a lot of font engines simply don't bother to support. That is unfortunate, and hopefully that will change as time goes on, but right now that's how it is.&lt;/p&gt;
&lt;p&gt;To make matters worse, the hinting in a Type2 outline is really "just hints". Type2 outlines can mark certain edges and points as needing to line up in some way, but it is up to the font engine to make sure that "lining up" happens sensibly, and (again because this is not a trivial task) a lot of font engines just ... don't bother.&lt;/p&gt;
&lt;p&gt;This leads people who are used to working with software that comes with a simple, or incomplete, font engine to claim that TTF is better than OTF because they look better, even though they don't: it's just the font engine not being good enough to deal with the space-optimised Type2 outline language, rather than the simplistic but "everything up front" TrueType outline language.&lt;/p&gt;
&lt;h2 id="-which-should-i-use-"&gt;"Which should I use?"&lt;/h2&gt;
&lt;p&gt;The real question tends to be which format you should use. If you're  a typeface designer, or a font engineer, I don't have to tell you which is to use, you already know the answer based on what you need to make, but if you're a font &lt;strong&gt;user&lt;/strong&gt;, which should you use? &lt;/p&gt;
&lt;p&gt;It depends entirely on what's available, and which engine you're going to use. If the font (or, font family) you want to use is only available in &lt;code&gt;.otf&lt;/code&gt; form, and you're going to use it in an excellent font engine like Adobe's own engine, then clearly: pick &lt;code&gt;.otf&lt;/code&gt;. If, on the other hand, you want a font that works best on the web, then it's really a toss-up between &lt;code&gt;.ttf&lt;/code&gt; and &lt;code&gt;.otf&lt;/code&gt; and the only real answer is "try them both, and see which one looks best". It might even be that at low point sizes the &lt;code&gt;.ttf&lt;/code&gt; looks best, but at higher point sizes, the &lt;code&gt;.otf&lt;/code&gt; looks better. If they're small fonts (i.e. the size of a JPEG image, which most fonts comfortably fall under) then why not just use both?&lt;/p&gt;
&lt;h2 id="more-to-come"&gt;More to come&lt;/h2&gt;
&lt;p&gt;In order to just get these posts out I'm going to keep some of them short, and this is one of the shorter ones, but rest assured that there's a lot to say about OpenType fonts, including how little most people know about them. And that's not an indictment, unless it's people espousing the virtue of one over the other without even realising they're both just OpenType fonts, only differing in the outline language, which is a large part of, but most certainly not the definitive aspect of, modern fonts.&lt;/p&gt;
&lt;p&gt;Next time I'll try to go into that statement a bit more: modern OpenType fonts are pretty dang complex pieces of software, and you could take the outline shapes for granted and still have a lot of amazingly detailed and rich data left to work with.&lt;/p&gt;
</description>
<category>Fonts</category>
<category>OpenType</category>
<category>TrueType</category>
<category>Type2</category>
<category>TTF</category>
<category>OTF</category>
<link>http://pomax.github.io/#gh-weblog-1449438115186</link>
<guid>http://pomax.github.io/#gh-weblog-1449438115186</guid>
<pubDate>Sun, 06 Dec 2015 21:41:55 GMT</pubDate>
</item>
<item>
<title> Github broke my blog, so I had to reset it...</title>
<description>&lt;p&gt;Github is usually pretty good when it comes to gh-pages and github.io hosting, but for some reason, an update to my pomax.github.io repository had broken whatever it is that github does when it deploys websites, to the point where even deleting my repository and then rebuilding it made things simply "not work".&lt;/p&gt;
&lt;p&gt;I ended up completely resetting the repository, which meant deleting it, which means all comments ever left by people are gone (I'm very sorry about that, thankfully the important thing about them was our conversation, not the historical record of that conversastion), and it turns out that github broke on the "gh-weblog" directory in the filessystem.  Renaming it to "gh-weblog-2" made things magically work (and boy do I wish I'd tried that first now, obviously), but creating a new dir "gh-weblog" and dropping files in there will land them into the repo, but keep them inaccesssisble on the github.io site. &lt;/p&gt;
&lt;p&gt;So if you were wondering where my articles had gone on Saturday, December 5th, now you know =(&lt;/p&gt;
</description>
<category>Github</category>
<category>Blog</category>
<category>Rebuilds</category>
<link>http://pomax.github.io/#gh-weblog-1449383023410</link>
<guid>http://pomax.github.io/#gh-weblog-1449383023410</guid>
<pubDate>Sun, 06 Dec 2015 06:23:43 GMT</pubDate>
</item>
<item>
<title> Bezier curves are not invariant under conformal mapping</title>
<description>&lt;p&gt;That's not a post title that'll sound very appealing to many people, but it's a question without an easy-to-google answer that I get asked more often than makes sense to keep answering on a case by case basis. So let me turn it into a URL on the internet instead.&lt;/p&gt;
&lt;p&gt;Invariance is defined as "any operation you can apply to the control points that define a Bezier curve, and then forming the curve, will yield the same curve as if you broke up the curve as a  sequence of individual points, and applied that operation to each of those, separately".&lt;/p&gt;
&lt;p&gt;Bezier curves are invariant under &lt;a href="https://en.wikipedia.org/wiki/Affine_transformation"&gt;affine linear transforms&lt;/a&gt;, which are those transforms that preserve parallel lines, but not necessarily distance between points or angles between lines. Basic affine linear transforms &lt;a href="https://en.wikipedia.org/wiki/Linear_map#Examples_of_linear_transformation_matrices"&gt;are&lt;/a&gt; rotation, reflection, translation, shearing, scaling, and projection.&lt;/p&gt;
&lt;p&gt;However, this is not the only class of transforms (obviously), and another transform that people tend to be interested in are &lt;a href="https://en.wikipedia.org/wiki/Conformal_map"&gt;conformal mappings&lt;/a&gt;, which preserve the (local) angle between lines, and this is a problem for Bezier curves.&lt;/p&gt;
&lt;p&gt;The simplest conformal mapping I can think of is the &lt;a href="https://en.wikipedia.org/wiki/Uniform_tilings_in_hyperbolic_plane"&gt;hyperbolic tiling&lt;/a&gt;, which maps the Euclidean ("rectangular") plane onto a circle plane instead, with a neat property:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the center of the Euclidean plane is the center of the circle.&lt;/li&gt;
&lt;li&gt;draw a line from the center, outward to infinity; this is a straight line in both the Euclidean plane and on the circle, but:&lt;/li&gt;
&lt;li&gt;a point along that line at distance D from the center of the Euclidean plane will lie at some distance D'&amp;lt;D from the "center" of the circle, and,&lt;/li&gt;
&lt;li&gt;any point along that line at twice the distance, E = 2D, on the Euclidean plane will lie on distance E' &amp;lt; 2D' - that is, outward travel at constant speed in the Euclidean plane, covering infinite distance, turns into monotone decreasing travel in terms of speed and distance, covering finite distance: you will never cross the "edge" of the circle, you just keep going slower and slower as you get closer and closer.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are an infinite number of functions that achieve this kind of mapping, but all of them preserve local angles: If two straight lines crossed each other at 37 degrees on the Euclidean plane, then the lines themselves will no longer be straight, but at the exact point of their intersection, the angle between them will still be 37 degrees.&lt;/p&gt;
&lt;p&gt;Now, if you conformally map  the points that define a Bezier curve, and then draw a new curve with those mapped points, you are not guaranteed to get the same curve as if you'd treated the curve a sequence of points that together draw the curve, and then conformally mapped all of those instead. And we can prove this with a single example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A mapping that turns straight lines into circular arcs is a conformal mapping, preserving local angles of intersection.&lt;/li&gt;
&lt;li&gt;Bezier curves can perfectly represent straight lines.&lt;/li&gt;
&lt;li&gt;Bezier curves cannot perfectly represent circular arcs.&lt;/li&gt;
&lt;li&gt;This mapping will turn geometry that can be represented by Bezier curves into geometry that cannot be represented by Bezier curves&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Q.E.D."&gt;QED&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another way to think about this is that Bezier curves are formed using (iterated) linear interpolation, which relies on straight lines staying linear. If we deform them to some non-linear form, then we cannot use linear interpolation and still find the same resulting points.&lt;/p&gt;
&lt;p&gt;So there you have it. Are Bezier curves invariant under conformal mapping? No, they are not.&lt;/p&gt;
</description>
<category>Maths</category>
<category>Bezier Curves</category>
<link>http://pomax.github.io/#gh-weblog-1449335750620</link>
<guid>http://pomax.github.io/#gh-weblog-1449335750620</guid>
<pubDate>Sat, 05 Dec 2015 17:15:50 GMT</pubDate>
</item></channel>
</rss>
